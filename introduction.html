
<!DOCTYPE html>


<html lang="en" data-content_root="./" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1. Probabilistic ML: What is it? Why use it? &#8212; Probabilistic Foundations of Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/css/course_schedule.css?v=244d4a68" />
    <link rel="stylesheet" type="text/css" href="_static/css/main.css?v=19873a65" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'introduction';</script>
    <link rel="canonical" href="https://mogu-lab.github.io/probabilistic-foundations-of-ml/introduction.html" />
    <link rel="icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="2. Introduction to Vectorization" href="vectorization-basics.html" />
    <link rel="prev" title="Probabilistic Foundations of ML" href="index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Probabilistic Foundations of Machine Learning - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Probabilistic Foundations of Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Probabilistic Foundations of ML
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">1. Probabilistic ML: What is it? Why use it?</a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-basics.html">2. Introduction to Vectorization</a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-advanced.html">3. Advanced Vectorization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Directed Graphical Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="probability-discrete.html">4. Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-conditional.html">5. Conditional Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-joint.html">6. Joint Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-data.html">7. The Ethics of Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frequentist Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mle-theory.html">8. Maximum Likelihood: Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="mle-code.html">9. Maximum Likelihood: Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html">10. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-continuous.html">11. Probability (Continuous)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-learning-from-data.html">12. The Ethics of Learning from Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Predictive Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="regression.html">13. Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification.html">14. Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural-networks.html">15. Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-selection.html">16. Model Selection &amp; Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-predictive-models.html">17. The Ethics of Predictive Models in Sociotechnical Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generative Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="gmms.html">18. Gaussian Mixture Models (Clustering)</a></li>
<li class="toctree-l1"><a class="reference internal" href="factor-analysis.html">19. Factor Analysis (Dimensionality Reduction)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-generative-models.html">20. The Ethics of Generative Models in Sociotechnical Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="priors-and-posteriors.html">21. Priors and Posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="posterior-predictives.html">22. Posterior Predictives</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-uncertainty-and-interpretability.html">23. The Ethics of Uncertainty and Interpretability in Human-AI Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Synthesis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ethics-of-ml.html">24. The Ethics of Machine Learning: A View from History</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/introduction.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probabilistic ML: What is it? Why use it?</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#your-role-at-the-intergalactic-hypothetical-hospital-ihh">1.1. Your Role at the Intergalactic Hypothetical Hospital (IHH)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-probabilistic-ml">1.2. What is Probabilistic ML?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-probabilistic-ml">1.3. Why Use Probabilistic ML?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#course-structure">1.4. Course Structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deconstructing-the-culture-of-ai">1.5. Deconstructing the Culture of AI</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probabilistic-ml-what-is-it-why-use-it">
<h1><span class="section-number">1. </span>Probabilistic ML: What is it? Why use it?<a class="headerlink" href="#probabilistic-ml-what-is-it-why-use-it" title="Link to this heading">#</a></h1>
<div class="tip admonition">
<p class="admonition-title">Congratulations!</p>
<p>You’ve been hired to join the machine learning team at the Intergalactic Hypothetical Hospital (IHH), where you’ll be leveraging routinely collected medical data to help improve treatment for beings across the galaxy.</p>
</div>
<section id="your-role-at-the-intergalactic-hypothetical-hospital-ihh">
<h2><span class="section-number">1.1. </span>Your Role at the Intergalactic Hypothetical Hospital (IHH)<a class="headerlink" href="#your-role-at-the-intergalactic-hypothetical-hospital-ihh" title="Link to this heading">#</a></h2>
<p><strong>About.</strong> The IHH is a research and teaching hospital located in the far corner of the universe. It serves a large number of intergalactic beings in the area. Like many modern hospitals, it collects large amounts of data about its patients (with their consent, of course), with the goal of leveraging this data to improve patient care. Unfortunately, doctors are incredibly busy focusing on the patients; when a new patient arrives, they don’t have time to inform their care based on the data they have. That is, they don’t have time to comb through all previously collected data, find similar patients, and determine how care for previous patients informs care for new patients. Moreover, they don’t have time to look at population-level trends or use data to research new treatment methods.</p>
<center>
    <img src="_static/figs/ihh.png" width="300px" />
</center>
<p><strong>The Machine Learning (ML) Team.</strong> As a result, the IHH has created a new ML team—the first of its kind! And they have hired you to join them. The goal of the team is to assist IHH researchers and clinicians in:</p>
<ul class="simple">
<li><p>Answering scientific questions, like better understanding the course of certain diseases.</p></li>
<li><p>Develop predictive models to identify patients at risk of certain diseases.</p></li>
</ul>
<p>The challenges they encounter in their data are unique, so as a result, you may have to develop <em>new ML methods</em> to address their unique problems.</p>
<p><strong>What is ML?</strong> Broadly speaking, ML is a paradigm of Artificial Intelligence (AI) that allows a computer to learn patterns from examples. In contrast, traditionally AI focused more on algorithmic/case-based reasoning. Now, the two terms are used more interchangeably. Nonetheless, let’s illustrate the difference.</p>
<ul class="simple">
<li><p><strong>AI via algorithmic/case-based reasoning.</strong> This paradigm is typically applied to problems where we have a good understanding of the mechanics. For example, suppose you wanted to play a game of tic-tac-toe against your computer. You can enumerate all possible courses of the game. You can program the computer to look at all possible future courses, and only choose ones in which it will win/tie.</p></li>
<li><p><strong>AI via extracting patterns from examples (i.e., ML).</strong> This paradigm is typically applied to problems in which we don’t have as good of an understanding—problems for which we cannot write down if-else rules, telling the computer what to do. In these cases, it’s easier to provide the computer with examples—inputs and outputs—and have the computer “figure out” how to map the inputs to the outputs. As in the case of the IHH, imagine you are testing the effect of a new medication. You want to predict a patient’s blood pressure as a function of the medication’s dose. It would be hard for you to write down precise rules (e.g. if dose is <span class="math notranslate nohighlight">\(x\)</span>, then blood pressure is <span class="math notranslate nohighlight">\(y\)</span>), since the biology underlying the medication is complicated, and influenced by each patient’s specific physiology (i.e. each patient reacts differently to the medication).</p></li>
</ul>
<p><strong>Your Role.</strong> Your role at the IHH requires you to consider three aspects of ML method application and development:</p>
<ol class="arabic simple">
<li><p><strong>Safety.</strong> Patient safety is everything. As such, the ML methods you develop must be accurate; an incorrect prediction may cause patients harm. Moreover, in cases where it’s not possible to make accurate predictions, your ML methods must indicate to its users the limits of their knowledge (i.e. they must quantify uncertainty). For example, if a patient arrives at the IHH whose profile is different than all previous patients your ML method has seen, it should <em>flag it</em> for careful clinician screening.</p></li>
<li><p><strong>Validity.</strong> The models you develop must be scientifically plausible; otherwise, IHH clinicians won’t be able to use them to advance clinical science.</p></li>
<li><p><strong>Ethics.</strong> Whenever computerized systems interact with humans, we have to proactively think of ethical challenges we will face; for example, what if our ML methods are less accurate for one group of patients? When things go wrong, who is held responsible?</p></li>
</ol>
<p>How can we address these challenges? You will use a specific paradigm of ML—the <em>probabilistic perspective</em>. This perspective provides us with tools to begin thinking about these questions.</p>
<p><strong>Diversity of backgrounds, identities, and lived experiences.</strong> But as you will see, this paradigm won’t be enough. On its own, it will not give us safe, valid, and ethical ML systems to use. Model development and application requires us to consider not just the technical components, but also the social components surrounding the technology. We call the overall system a <em>sociotechnical system</em>:</p>
<div class="canva-centered-embedding">
  <div class="canva-iframe-container" style="max-width: none;">
    <iframe loading="lazy" class="canva-iframe"
      src="https:&#x2F;&#x2F;www.canva.com&#x2F;design&#x2F;DAGNeSJW7Mk&#x2F;rP-g5in9AGP2MJmrOydpqw&#x2F;view?embed">
    </iframe>
  </div>
</div>
<p>Developing safe, valid, and ethical ML systems is a multi-faceted, open challenge—one that requires a diversity of perspectives. Luckily, the IHH’s hiring practice values a diversity of backgrounds, identities, and lived experiences. <em>This is our biggest asset.</em></p>
</section>
<section id="what-is-probabilistic-ml">
<h2><span class="section-number">1.2. </span>What is Probabilistic ML?<a class="headerlink" href="#what-is-probabilistic-ml" title="Link to this heading">#</a></h2>
<p>In a loose sense, there are two main paradigms to ML. There’s what we’ll call here the <em>optimization perspective</em> and the <em>probabilistic perspective</em>. These two perspectives aren’t mutually exclusive—there are ML methods that can be described by both—but there are also methods that uniquely belong to each. Even more importantly, each accompanies a specific way of thinking.</p>
<p><strong>The Optimization Perspective.</strong> In the optimization perspective, we formalize our goal into a <em>loss</em> or <em>objective</em> function. For example, suppose we’re given a data set, <span class="math notranslate nohighlight">\((x_1, y_1), (x_2, y_2), \dots, (x_N, y_N)\)</span>, in which <span class="math notranslate nohighlight">\(x\)</span> is the dose of medication and <span class="math notranslate nohighlight">\(y\)</span> is the resulting blood pressure. Our goal is to learn to predict the <span class="math notranslate nohighlight">\(y\)</span>’s from the <span class="math notranslate nohighlight">\(x\)</span>’s. That is, we want to learn a function <span class="math notranslate nohighlight">\(f\)</span> that, given a value of <span class="math notranslate nohighlight">\(x\)</span> will return <span class="math notranslate nohighlight">\(y\)</span>. We can encode our goal into the following loss function:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3a9fbf9f-6a55-4536-81ea-53ac9e1e161e">
<span class="eqno">(1.1)<a class="headerlink" href="#equation-3a9fbf9f-6a55-4536-81ea-53ac9e1e161e" title="Permalink to this equation">#</a></span>\[\begin{align}
\text{loss} = \underbrace{\frac{1}{N}\sum\limits_{n=1}^N}_{\text{average}} \text{ } \underbrace{| y_n - f(x_n) |}_{\text{error}}
\end{align}\]</div>
<p>This function computes the average error between the predictions, <span class="math notranslate nohighlight">\(f(x_n)\)</span>, and the data <span class="math notranslate nohighlight">\(y_n\)</span>. Then by finding a predictor <span class="math notranslate nohighlight">\(f\)</span> that <em>minimizes</em> our loss, we find a predictor that makes accurate predictions on our data. We then hope that our <span class="math notranslate nohighlight">\(f\)</span> will continue to make accurate predictions for future data points. The name of the game behind the optimization perspective is coming up with a loss function that encodes your goals.</p>
<p><strong>The Probabilistic Perspective.</strong> In the probabilistic perspective, we take a different approach. Instead of directly writing down a loss function that encodes our goal, we formalize our beliefs about the data into a “story” of how the data was generated. As an example, consider the model that predicts blood pressure given a dose of medication. For this model, our story can be something like:</p>
<ol class="arabic simple">
<li><p>Measure the dose, <span class="math notranslate nohighlight">\(x\)</span>, and give it to the patient.</p></li>
<li><p>Due to the medicine, the patient’s true blood pressure is now <span class="math notranslate nohighlight">\(\mu(x)\)</span>. Notice that <span class="math notranslate nohighlight">\(\mu(x)\)</span> is a function of <span class="math notranslate nohighlight">\(x\)</span>, since it depends on the dose.</p></li>
<li><p>We measure the patient’s blood pressure. Since the device’s sensors aren’t perfect, we assume the <em>measured</em> blood pressure, <span class="math notranslate nohighlight">\(y\)</span>, is near the <em>true</em> blood pressure, <span class="math notranslate nohighlight">\(\mu(x)\)</span>. Specifically, we assume it’s <span class="math notranslate nohighlight">\(\pm \sigma\)</span> around <span class="math notranslate nohighlight">\(\mu(x)\)</span>, with a higher probability of being closer to <span class="math notranslate nohighlight">\(\mu(x)\)</span>.</p></li>
</ol>
<figure class="align-center" id="intro-story-regression">
<a class="reference internal image-reference" href="_images/example_regression_intro.png"><img alt="_images/example_regression_intro.png" src="_images/example_regression_intro.png" style="width: 500px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.1 </span><span class="caption-text">A visual illustration of the generative story.</span><a class="headerlink" href="#intro-story-regression" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>This story describes how the data is generated. If we were to write it with more mathematical specificity, as we will learn to do in this course, this story is a <em>probabilistic model</em>.</p>
<p>Notice that there are a few missing pieces in the story. First, we didn’t say what <span class="math notranslate nohighlight">\(\mu\)</span> is—just that it’s a function. Second, we didn’t say what <span class="math notranslate nohighlight">\(\sigma\)</span> is. Using algorithms from statistics, we will fit the model to data and estimate these missing pieces. Some of these algorithms will end up minimizing some loss function (like in the optimization perspective), and some will not. Even if we end up with a loss function, the <em>process</em> that led us to this objective function will have a very specific flavor and philosophical underpinning—it will always be concerned with probability distributions in some way.</p>
<p>Next, let’s highlight some of the advantages of the paradigm.</p>
</section>
<section id="why-use-probabilistic-ml">
<h2><span class="section-number">1.3. </span>Why Use Probabilistic ML?<a class="headerlink" href="#why-use-probabilistic-ml" title="Link to this heading">#</a></h2>
<p><strong>Advantage 1: Distributions <span class="math notranslate nohighlight">\(\rightarrow\)</span> Uncertainty Quantification and Generative Models.</strong> In safety-critical applications of ML, uncertainty matters just as much as accuracy. The probabilistic perspective will allow us to capture the uncertainty of our method’s predictions (they will tell us when they are unsure about a prediction). What is uncertainty exactly? and how will we quantify it? Stick around to find out.</p>
<p>Next, the probabilistic perspective will allow us to develop <em>generative models</em>; for example, models that can convert text into high-resolution images, generate new musical compositions, etc. These models are probabilistic because they learn the <em>distribution</em> of the data they are given.</p>
<figure class="align-center" id="sketchgan">
<a class="reference internal image-reference" href="_images/sketchgan.gif"><img alt="_images/sketchgan.gif" src="_images/sketchgan.gif" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.2 </span><span class="caption-text">Example of a Generative AI that generates a photo-realistic image from a sketch, taken from <a class="reference external" href="https://www.casualganpapers.com/few-shot-user-guided-gan-domain-adaptation/Sketch-Your-Own-GAN-explained.html" rel="noreferrer" target="_blank">this website</a>.</span><a class="headerlink" href="#sketchgan" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Advantage 2: Unified Framework <span class="math notranslate nohighlight">\(\rightarrow\)</span> Create/Analyze New ML Methods.</strong> You may have heard of different “types” of ML algorithms, like supervised ML and unsupervised ML (no worries if you haven’t—the details aren’t important):</p>
<figure class="align-center" id="types-of-ml">
<a class="reference internal image-reference" href="_images/types-of-ml.png"><img alt="_images/types-of-ml.png" src="_images/types-of-ml.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.3 </span><span class="caption-text">Types of ML methods, adapted from <a class="reference external" href="https://resources.experfy.com/ai-ml/coding-deep-learning-for-beginners-types-of-machine-learning/" rel="noreferrer" target="_blank">this website</a>.</span><a class="headerlink" href="#types-of-ml" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Supervised ML typically refers to predictive methods—methods that predict a “label” <span class="math notranslate nohighlight">\(y\)</span> from an input <span class="math notranslate nohighlight">\(x\)</span> (as we did in our blood pressure example). The label “supervises” the method to give us the desired output. In contrast, unsupervised ML are only given inputs <span class="math notranslate nohighlight">\(x\)</span> and are asked to predict some label with useful properties. In this sense, they are “unsupervised.” For example, given a collection of patients’ medical histories as inputs, <span class="math notranslate nohighlight">\(x\)</span>, we may want to cluster similar patients. We can then see if groups of similar patients benefit from similar treatments, etc.</p>
<p>This taxonomy of ML methods largely comes from the non-probabilistic perspective, since under this perspective, each method requires a different derivation, different fitting algorithms, and different theoretical analyses to understand its properties. This poses two challenges for developing new ML methods:</p>
<ol class="arabic simple">
<li><p>It’s hard to come up with a brand new ML method if we don’t have a unified framework for developing methods.</p></li>
<li><p>Every method you develop will need a brand new implementation, analysis, and justification—that’s a lot of work!</p></li>
</ol>
<p>In contrast, the probabilistic perspective allows us to derive all of these methods under a <em>unified framework</em>. This framework will allow us to develop unique methods more easily—e.g. methods that have supervised <em>and</em> unsupervised components—and to better analyze these methods. We will therefore abandon this taxonomy in the class.</p>
<p><strong>Advantage 3: Explicit Modeling Assumptions <span class="math notranslate nohighlight">\(\rightarrow\)</span> Highlights Subjectivity.</strong> While we’d like to think of ML systems as data-driven wizardry—you just give it data and it does the “right thing”—we’ll show in this course that <em>this is a myth</em>. It’s not theoretically possible to build such a system; all systems make assumptions. For safety-critical applications, like the ones at the IHH, it’s important that these assumptions are <em>explicit</em>. This is another strength of the probabilistic paradigm. In expressing our beliefs about the data via <em>generative story</em>, we list all assumptions we’ve made about the data. This will allow us to better interrogate our assumptions when our method behaves poorly (e.g. when our method is inaccurate, unfair, over-confident, etc.).</p>
</section>
<section id="course-structure">
<h2><span class="section-number">1.4. </span>Course Structure<a class="headerlink" href="#course-structure" title="Link to this heading">#</a></h2>
<p>This course consists of several parts, outlined below. We designed the course to cover the probabilistic model paradigm quickly (parts 1-3), so we can instantiate it in a variety of ways to derive popular ML methods (parts 4-5). The idea behind this design is that it highlights how all ML methods can be unified under the same paradigm. In each part of the course, we will always:</p>
<ul class="simple">
<li><p><strong>Center concrete tasks from the IHH.</strong> This is because it’s not possible to responsibly and ethically evaluate an ML model without considering the context in which it will be used.</p></li>
<li><p><strong>Center ethics.</strong> As we hinted before, the course will highlight how ML systems are inherently subjective, and informed by implicit societal values and norms. Because of this, we must question the ethics implied in our goals, methods, evaluation procedures, etc.</p></li>
</ul>
<p><strong>Part 1: Introduction.</strong> Before starting to learn ML, we’ll get comfortable with <code class="docutils literal notranslate"><span class="pre">Jax</span></code>, a popular Python library for high-performance numerical computing. This library powers many ML libraries and is popular amongst ML researchers. We will use it as the basis for all code we write in the course.</p>
<p><strong>Part 2: Directed Graphical Models.</strong> We’ll then shift over to learning the <em>language</em> of probabilistic models. That is, we’ll learn how to specify probabilistic models (like the generative story above), using probability distributions. We will start to gain intuition for what types of models are useful for which tasks. Will do all of this in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>, a probabilistic programming language. <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> will allow us to translate our generative story directly into code we can run.</p>
<p><strong>Part 3: Frequentist Learning.</strong> Using the language we developed in the previous part, we will now introduce our first model-fitting algorithm. With the language to express models <em>and</em> an algorithm to fit models to data, we will next begin to explore different types of commonly used ML models: predictive and generative models.</p>
<p><strong>Part 4: Predictive Models.</strong> The first model class we’ll explore is predictive models. As the name suggests, these models are designed to make predictions (like in the dose / blood pressure example), and represent “supervised learning.” We will also learn how make our models expressive using tools from Deep Learning (specifically, neural networks).</p>
<p><strong>Part 5: Generative Models.</strong> The second model class we’ll explore is generative models. As the name suggests, these models can generate realistic-looking synthetic data (like those text-to-image models you may have played with).</p>
<p><strong>Part 6: Bayesian Inference.</strong> Now that we’ve instantiated the probabilistic ML paradigm a number of times, we’ll introduce a second model-fitting algorithm. This model-fitting algorithm will allow us to quantify uncertainty.</p>
<p><strong>Part 7: Special Topics.</strong> Finally, we will connect the topics covered in class to current probabilistic ML research.</p>
</section>
<section id="deconstructing-the-culture-of-ai">
<h2><span class="section-number">1.5. </span>Deconstructing the Culture of AI<a class="headerlink" href="#deconstructing-the-culture-of-ai" title="Link to this heading">#</a></h2>
<p>We, as a society, hold beliefs about science that may be romanticized and inaccurate. These ideas can be exclusionary in the way we define a typical scientist and how science is done. These notions about science can also become obstacles for us as a community to perform rigorous, inclusive, and useful science, impede us individually in our professional growth, by contributing to unrealistic self-expectations (and therefore poor mental health), and hinder our ability to build supportive academic communities. What are these misconceptions? How can we address them?</p>
<div class="admonition-exercise-societal-misconceptions-about-ai admonition">
<p class="admonition-title">Exercise: Societal Misconceptions about AI</p>
<p><strong>Part 1:</strong> Watch <a class="reference external" href="https://www.youtube.com/watch?v=WNu6fRo_7fg" rel="noreferrer" target="_blank">this video</a> of Iron Man developing and debugging a new suit. What societal misconceptions about CS/engineering/AI does this video endorse? Think both about <em>who</em> does computer science, as well as about <em>what’s</em> the day-to-day experience of doing CS.</p>
<p><strong>Part 2:</strong> Below is a collection of <em>common, reasonable, and expected</em> experiences in CS/AI/ML classes—you may find yourselves relating to these (the course staff certainly did!). In addition to representing a common, valid experience, each statement is further endorsed by common societal misconceptions. Can you identify the misconceptions behind each statement?</p>
<ul class="simple">
<li><p>I’m worried this class will be too difficult in terms of math.</p></li>
<li><p>I’m worried this class will be too difficult in terms of coding.</p></li>
<li><p>I’m worried I don’t have the right background for the class.</p></li>
<li><p>I’m worried that my background/skill set will not be valued by my peers.</p></li>
<li><p>I’m worried I won’t do well in the class.</p></li>
</ul>
<p><strong>Part 3:</strong> Individually and as a community, how can we address these common challenges?</p>
</div>
<p><strong>Acknowledgements.</strong> This section is adapted from <a class="reference external" href="https://arxiv.org/pdf/2208.12650" rel="noreferrer" target="_blank">Yaniv Yacoby’s offering of CS290 at Harvard</a>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Probabilistic Foundations of ML</p>
      </div>
    </a>
    <a class="right-next"
       href="vectorization-basics.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Introduction to Vectorization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#your-role-at-the-intergalactic-hypothetical-hospital-ihh">1.1. Your Role at the Intergalactic Hypothetical Hospital (IHH)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-probabilistic-ml">1.2. What is Probabilistic ML?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-probabilistic-ml">1.3. Why Use Probabilistic ML?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#course-structure">1.4. Course Structure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deconstructing-the-culture-of-ai">1.5. Deconstructing the Culture of AI</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <footer>
  <div class="flex-shrink-0 container">
    <div class="row align-items-center">
      <div class="col-8">

        <p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">Probabilistic Foundations of Machine Learning</span> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://yanivyacoby.github.io/" target="_blank">Yaniv Yacoby</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1" alt=""></a></p>

      </div>      
      <div class="col-4">
        <img src="_static/img/wc-logo-blue.png" alt="Wellesley College Logo" class="only-light" style="max-width: 120px; float: right; display: block;"/>
        <img src="_static/img/wc-logo-white.png" alt="Wellesley College Logo" class="only-dark" style="max-width: 120px; float: right; display: block;"/>
      </div>
    </div>    
  </div>  
</footer>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>