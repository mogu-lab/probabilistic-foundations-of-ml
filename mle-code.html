
<!DOCTYPE html>


<html lang="en" data-content_root="./" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>9. Maximum Likelihood: Code &#8212; Probabilistic Foundations of Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/css/course_schedule.css?v=244d4a68" />
    <link rel="stylesheet" type="text/css" href="_static/css/main.css?v=19873a65" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'mle-code';</script>
    <link rel="canonical" href="https://mogu-lab.github.io/probabilistic-foundations-of-ml/mle-code.html" />
    <link rel="icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="10. Optimization" href="optimization.html" />
    <link rel="prev" title="8. Maximum Likelihood: Theory" href="mle-theory.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Probabilistic Foundations of Machine Learning - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Probabilistic Foundations of Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Probabilistic Foundations of ML
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. Probabilistic ML: What is it? Why use it?</a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-basics.html">2. Introduction to Vectorization</a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-advanced.html">3. Advanced Vectorization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Directed Graphical Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="probability-discrete.html">4. Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-conditional.html">5. Conditional Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-joint.html">6. Joint Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-data.html">7. The Ethics of Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frequentist Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mle-theory.html">8. Maximum Likelihood: Theory</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">9. Maximum Likelihood: Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html">10. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-continuous.html">11. Probability (Continuous)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-learning-from-data.html">12. The Ethics of Learning from Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Predictive Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="regression.html">13. Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification.html">14. Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural-networks.html">15. Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-selection.html">16. Model Selection &amp; Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-predictive-models.html">17. The Ethics of Predictive Models in Sociotechnical Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generative Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="gmms.html">18. Gaussian Mixture Models (Clustering)</a></li>
<li class="toctree-l1"><a class="reference internal" href="factor-analysis.html">19. Factor Analysis (Dimensionality Reduction)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-generative-models.html">20. The Ethics of Generative Models in Sociotechnical Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="priors-and-posteriors.html">21. Priors and Posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="posterior-predictives.html">22. Posterior Predictives</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-uncertainty-and-interpretability.html">23. The Ethics of Uncertainty and Interpretability in Human-AI Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Synthesis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ethics-of-ml.html">24. The Ethics of Machine Learning: A View from History</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/mle-code.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Maximum Likelihood: Code</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-generating-process">9.1. The Data Generating Process</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-the-generative-process-or-model-in-numpyro">9.2. Implementing the “Generative Process” (or Model) in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="maximum-likelihood-code">
<h1><span class="section-number">9. </span>Maximum Likelihood: Code<a class="headerlink" href="#maximum-likelihood-code" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import some helper functions (please ignore this!)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">utils</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span> 
<span class="kn">import</span><span class="w"> </span><span class="nn">probabilistic_foundations_of_ml</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pfml</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Context:</strong> Now that we can describe our objective—to find the model parameters that maximize the probability of the observed data—we are ready to translate it into code.</p>
<p><strong>Challenge:</strong> But how can we easily implement this optimization procedure generally? That is, how can we perform the MLE on <em>any model</em> of interest? This is the strength of a probabilistic programming language like <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>. Probabilistic programming languages provide us with the necessary <em>abstraction</em> for representing probabilistic models, so that under the hood, <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> can help us do the heavy lifting.</p>
<p><strong>Outline:</strong></p>
<ul class="simple">
<li><p>Use our knowledge of sampling from joint distribution to write down a procedure for sampling from the joint data likelihood.</p></li>
<li><p>Directly translate this procedure to <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>.</p></li>
</ul>
<section id="the-data-generating-process">
<h2><span class="section-number">9.1. </span>The Data Generating Process<a class="headerlink" href="#the-data-generating-process" title="Link to this heading">#</a></h2>
<p>In <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>, models are implemented as Python functions. In these functions, we describe the model’s “generative process”—or, a procedure we use to sample the observed data. You just learned how to represent a whole data set using a model (using the plate notation above). We will therefore walk through a specific example that we will then code in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>.</p>
<p><strong>Example:</strong> We’ll illustrate how to do this using an example. Suppose we want to model the joint distribution of the day-of-the-week, <span class="math notranslate nohighlight">\(D\)</span>, and whether a patient is intoxicated, <span class="math notranslate nohighlight">\(I\)</span>. We can do this via the model,</p>
<div class="amsmath math notranslate nohighlight" id="equation-fb2c3de1-7b14-46be-9e6e-f0ab6f4a69d3">
<span class="eqno">(9.1)<a class="headerlink" href="#equation-fb2c3de1-7b14-46be-9e6e-f0ab6f4a69d3" title="Permalink to this equation">#</a></span>\[\begin{align}
p(\mathcal{D}; \pi, \rho) &amp;= \prod\limits_{n=1}^N p_{I | D}(i_n | d_n; \rho) \cdot p_D(d_n; \pi).
\end{align}\]</div>
<p>In this model,</p>
<p><strong>(a)</strong> <em>Marginal:</em> <span class="math notranslate nohighlight">\(p_D(\cdot; \pi)\)</span> is a distribution over the days of the week. We will therefore define it to be a Categorical distribution:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b520315e-3da8-499c-8c82-7306f2e4189e">
<span class="eqno">(9.2)<a class="headerlink" href="#equation-b520315e-3da8-499c-8c82-7306f2e4189e" title="Permalink to this equation">#</a></span>\[\begin{align}
p_D(\cdot; \pi) = \mathrm{Cat}(\pi).
\end{align} \]</div>
<p>Here, the parameter <span class="math notranslate nohighlight">\(\pi\)</span> is a 7-dimensional array describing the probability of an observation coming from each of the 7 days of the week. That is, the probability of <span class="math notranslate nohighlight">\(D = d_n\)</span> is given by the <span class="math notranslate nohighlight">\(d_n\)</span>-th entry of <span class="math notranslate nohighlight">\(\pi\)</span>: i.e. <span class="math notranslate nohighlight">\(p_{D}(d_n; \pi) = \pi_{d_n}\)</span>.</p>
<p><strong>(b)</strong> <em>Conditional:</em> <span class="math notranslate nohighlight">\(p_{I | D}(\cdot | d_n; \rho)\)</span> is the probability that a patient arrives at the ER with intoxication given that <span class="math notranslate nohighlight">\(D = d_n\)</span>. Since “intoxication” is a binary outcome, we will model it using a Bernoulli. However, recall that the probability of intoxication <em>changes with the day of the week</em>—on some days, we’re more likely to treat patients with intoxication. The parameter of the Bernoulli distribution therefore needs to change depending on the day of the week. We therefore define:</p>
<div class="amsmath math notranslate nohighlight" id="equation-f9fe0df9-8f2d-4e17-8b7a-0240c8cd55fa">
<span class="eqno">(9.3)<a class="headerlink" href="#equation-f9fe0df9-8f2d-4e17-8b7a-0240c8cd55fa" title="Permalink to this equation">#</a></span>\[\begin{align}
p_{I | D}(i_n | d_n; \rho) = \mathrm{Ber}(\rho_{d_n}).
\end{align} \]</div>
<p>By this, we mean that <span class="math notranslate nohighlight">\(\rho\)</span> is a 7-dimensional vector, where the <span class="math notranslate nohighlight">\(d_n\)</span>-th entry, denoted by <span class="math notranslate nohighlight">\(\rho_{d_n}\)</span>, is the probability of intoxication on day <span class="math notranslate nohighlight">\(d_n\)</span>.</p>
<p><strong>Valid Parameter Values:</strong> Since each entry of <span class="math notranslate nohighlight">\(\rho\)</span> represents a Bernoulli distribution, each entry must be on between 0 and 1 (i.e. on the “unit interval”). And since <span class="math notranslate nohighlight">\(\pi\)</span> represents a Categorical distribution, its entries must sum to 1 (a fancy name of this is that <span class="math notranslate nohighlight">\(\pi\)</span> lies on a “simplex”). We note this briefly because we will have to communicate to <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> the valid values these parameters may take on (but don’t worry, this isn’t hard to do).</p>
<p><strong>Generative Process:</strong> For this model, we assume the data was sampled (or generated) as follows:</p>
<ul class="simple">
<li><p><em>Step 1:</em> We choose an <em>initial guess</em> for <span class="math notranslate nohighlight">\(\pi\)</span> and <span class="math notranslate nohighlight">\(\rho\)</span>. Our guess doesn’t need to be good, since <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> help us find better values via MLE.</p></li>
<li><p><em>Step 2:</em> For every <span class="math notranslate nohighlight">\(n = 1, \dots, N\)</span>:</p>
<ul>
<li><p><em>Step 2a:</em> We sample <span class="math notranslate nohighlight">\(d_n\)</span> from the marginal, <span class="math notranslate nohighlight">\(d_n \sim p_D(\cdot; \pi) = \mathrm{Cat}(\pi)\)</span>.</p></li>
<li><p><em>Step 2b:</em> Given the specific value of <span class="math notranslate nohighlight">\(d_n\)</span> from Step 2a, we sample from the conditional, <span class="math notranslate nohighlight">\(i_n | d_n \sim p_{I | D}(\cdot | d_n; \rho) = \mathrm{Ber}(\rho_{d_n})\)</span>.</p></li>
</ul>
</li>
</ul>
<p>This generative process is what we will translate into <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>, line for line.</p>
<div class="admonition-exercise-practice-with-generative-processes admonition">
<p class="admonition-title">Exercise: Practice with generative processes</p>
<p><strong>Part 1:</strong> Write the data generative process for the IHH ER model (described in the exercise in the previous chapter)</p>
<p><strong>Part 2:</strong> For each of the DGMs below, write the data-generating process. You can find graphical models for them in the exercise of the previous chapter.</p>
<p>(i) Predictive Models</p>
<p>(ii) Gaussian Mixture Models</p>
<p>(iii) Latent Dirichlet Allocation</p>
<p>(iv) Conditional Subspace Variational Autoencoder</p>
<p>(v) Hidden Markov Models</p>
</div>
</section>
<section id="implementing-the-generative-process-or-model-in-numpyro">
<h2><span class="section-number">9.2. </span>Implementing the “Generative Process” (or Model) in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code><a class="headerlink" href="#implementing-the-generative-process-or-model-in-numpyro" title="Link to this heading">#</a></h2>
<p>Now that we have our generative process, we can go ahead and implement it in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>.</p>
<p><strong>The Duality of <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> Models.</strong> Recall that, so far, we had to write two separate methods to <em>sample</em> data from a <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> model and to compute the probability of data under a <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> model. Following this approach, you’d expect that to perform the MLE, we’ll need to write yet another function. But as you can see, if we had to write a function for every task we want to perform with a model, this quickly becomes cumbersome. Instead, can we only have <em>one</em> function that represents that model, from which we can both sample, evaluate the probability, and perform the MLE? This is what we will do next; we will use <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> primitives to define models that can be used for these dual purposes.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> Primitives.</strong> Specifically, we will use three <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> primitives. These primitives will communicate to <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> everything it needs to know to do the heavy lifting of sampling, evaluating, and performing the MLE. The primitives are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">numpyro.param</span></code>, which represents model parameters</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">numpyro.sample</span></code>, which represents an RV</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">numpyro.plate</span></code>, which represents i.i.d sampling using the “plate” notation</p></li>
</ul>
<p>We’ll walk you through how to use these primitives to build the model, but we additionally recommend you get in the habit of reading the <a class="reference external" href="https://num.pyro.ai/en/stable/primitives.html" rel="noreferrer" target="_blank">relevant documentation</a>.</p>
<p><strong>Model:</strong> We start by creating a function to represent our model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">model_of_intoxication_and_day</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">pass</span>
</pre></div>
</div>
<p>This function takes in several arguments:</p>
<ul class="simple">
<li><p>The total number of observations, <span class="math notranslate nohighlight">\(N\)</span>.</p></li>
<li><p>Optional arrays describing the observations. That is, <code class="docutils literal notranslate"><span class="pre">d</span></code> represents an array of all <span class="math notranslate nohighlight">\(N\)</span> days of the week, and <code class="docutils literal notranslate"><span class="pre">i</span></code> represents all <span class="math notranslate nohighlight">\(N\)</span> binary values intoxication-yes/no. When sampling data from the model, we do not pass in <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">i</span></code>, but when performing the MLE, we do need to pass them in. This is because the MLE objective will try to find settings of <span class="math notranslate nohighlight">\(\pi, \rho\)</span> that will make our observed data most likely.</p></li>
</ul>
<p>Next, we can go through each step of the generative process above and translate it into <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>, line by line:</p>
<p><strong>Step 1:</strong> We define our parameters using the <code class="docutils literal notranslate"><span class="pre">numpyro.param</span></code> primitive.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pi</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span>
    <span class="s1">&#39;pi&#39;</span><span class="p">,</span>                          <span class="c1"># A name used by NumPyro</span>
    <span class="n">init_value</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="o">/</span> <span class="mf">7.0</span><span class="p">,</span>  <span class="c1"># Initial value for pi: [1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7]</span>
    <span class="n">constraint</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">simplex</span><span class="p">,</span>          <span class="c1"># Entries of pi must sum to 1 (i.e. lie on a &quot;simplex&quot;)</span>
<span class="p">)</span>

<span class="n">rho</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span>
    <span class="s1">&#39;rho&#39;</span><span class="p">,</span>                         <span class="c1"># A name used by NumPyro</span>
    <span class="n">init_value</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># Initial value for rho: [0.5, 0.5, 0.5, 0.5, 0.5. 0.5, 0.5]</span>
    <span class="n">constraint</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">unit_interval</span><span class="p">,</span>    <span class="c1"># Each entry of rho must be in [0, 1] (i.e. lie in &quot;unit interval&quot;)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>You can find more types of constraints listed <a class="reference external" href="https://num.pyro.ai/en/stable/_modules/numpyro/distributions/constraints.html" rel="noreferrer" target="_blank">here</a>.</p>
<p><strong>Step 2:</strong> We create a “plate” to indicate <span class="math notranslate nohighlight">\(N\)</span> i.i.d observations using <code class="docutils literal notranslate"><span class="pre">numpyro.plate</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="k">pass</span>
</pre></div>
</div>
<p><strong>Step 2a:</strong> Inside the plate, we sample <span class="math notranslate nohighlight">\(d_n\)</span> from the marginal, <span class="math notranslate nohighlight">\(d_n \sim p_D(\cdot; \pi) = \mathrm{Cat}(\pi)\)</span>, using <code class="docutils literal notranslate"><span class="pre">numpyro.sample</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define marginal as Categorical using pi</span>
<span class="n">p_D</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span>

<span class="c1"># Sample from the marginal</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">p_D</span><span class="p">,</span> <span class="n">obs</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>  
</pre></div>
</div>
<p><strong>Step 2b:</strong> Inside the plate, we use the specific value of <span class="math notranslate nohighlight">\(d_n\)</span> from Step 2a to sample from the conditional, <span class="math notranslate nohighlight">\(i_n | d_n \sim p_{I | D}(\cdot | d_n; \rho) = \mathrm{Ber}(\rho_{d_n})\)</span> using <code class="docutils literal notranslate"><span class="pre">numpyro.sample</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define conditional as Bernoulli. Notice rho[d] to access the d-th entry of rho</span>
<span class="n">p_I_given_D</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">rho</span><span class="p">[</span><span class="n">d</span><span class="p">])</span>

<span class="c1"># Sample from the conditional </span>
<span class="n">i</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="n">p_I_given_D</span><span class="p">,</span> <span class="n">obs</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Putting everything together:</strong> We now have a model that <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> understands and can perform MLE on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.random</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jrandom</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">D</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro.distributions.constraints</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">C</span>


<span class="k">def</span><span class="w"> </span><span class="nf">model_of_intoxication_and_day</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span>
        <span class="s1">&#39;pi&#39;</span><span class="p">,</span> 
        <span class="n">init_value</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="o">/</span> <span class="mf">7.0</span><span class="p">,</span> 
        <span class="n">constraint</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">simplex</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="n">rho</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span>
        <span class="s1">&#39;rho&#39;</span><span class="p">,</span> 
        <span class="n">init_value</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">,</span> 
        <span class="n">constraint</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">unit_interval</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="k">with</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="n">p_D</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">p_D</span><span class="p">,</span> <span class="n">obs</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>

        <span class="n">p_I_given_D</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">rho</span><span class="p">[</span><span class="n">d</span><span class="p">])</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="n">p_I_given_D</span><span class="p">,</span> <span class="n">obs</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Sampling from the Model:</strong> We created a helper function for you, <code class="docutils literal notranslate"><span class="pre">pfml.sample_generative_process</span></code>, to sample from this model. The function takes in a <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> model, a random generator key, and then all arguments your model takes in (in this case, <code class="docutils literal notranslate"><span class="pre">N,</span> <span class="pre">d=None,</span> <span class="pre">i=None</span></code>). Note that:</p>
<ul class="simple">
<li><p>We haven’t yet fit the model to the data. As such, the data we generate below will use our “initial guess” for <span class="math notranslate nohighlight">\(\pi\)</span> and <span class="math notranslate nohighlight">\(\rho\)</span>. Later in the course, we will see why being able to sample data from a model before fitting it may be helpful.</p></li>
<li><p>We pass in <code class="docutils literal notranslate"><span class="pre">None</span></code> for the observed data (i.e. <code class="docutils literal notranslate"><span class="pre">d=None,</span> <span class="pre">i=None</span></code>). This is because when sampling, we only want to know <em>how many</em> samples we want to generate (denoted by <code class="docutils literal notranslate"><span class="pre">N</span></code>), as opposed to giving it the data, which is only useful for evaluating the MLE objective.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">20</span> <span class="c1"># Number of samples to generate</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Random generator key to use</span>

<span class="n">pfml</span><span class="o">.</span><span class="n">sample_generative_process</span><span class="p">(</span><span class="n">model_of_intoxication_and_day</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;pi&#39;: Array([0.14285714, 0.14285714, 0.14285714, 0.14285714, 0.14285714,
        0.14285714, 0.14285714], dtype=float64),
 &#39;rho&#39;: Array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], dtype=float64),
 &#39;d&#39;: Array([0, 6, 5, 4, 4, 4, 5, 6, 0, 6, 1, 4, 2, 4, 4, 3, 5, 4, 6, 6], dtype=int64),
 &#39;i&#39;: Array([0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1], dtype=int64)}
</pre></div>
</div>
</div>
</div>
<p><strong>Performing the MLE:</strong> We will now perform the MLE using another helper function we’ve created. Recall that the MLE for this model is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-123d988d-d6c8-4315-9629-ca3968ff9823">
<span class="eqno">(9.4)<a class="headerlink" href="#equation-123d988d-d6c8-4315-9629-ca3968ff9823" title="Permalink to this equation">#</a></span>\[\begin{align}
\pi^\text{MLE}, \rho^\text{MLE} &amp;= \mathrm{argmax}_{\pi, \rho} \prod\limits_{n=1}^N p_{I | D}(i_n | d_n; \rho) \cdot p_D(d_n; \pi) \\
&amp;= \mathrm{argmax}_{\pi, \rho} \log \prod\limits_{n=1}^N p_{I | D}(i_n | d_n; \rho) \cdot p_D(d_n; \pi) \\
&amp;= \mathrm{argmax}_{\pi, \rho} \sum\limits_{n=1}^N \log p_{I | D}(i_n | d_n; \rho) + \log p_D(d_n; \pi)
\end{align}\]</div>
<p>First, we’ll load in the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import a bunch of libraries we&#39;ll be using below</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">D</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>

<span class="c1"># Load the data into a pandas dataframe</span>
<span class="n">csv_fname</span> <span class="o">=</span> <span class="s1">&#39;data/IHH-ER.csv&#39;</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_fname</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;Patient ID&#39;</span><span class="p">)</span>

<span class="c1"># Print a random sample of patients, just to see what&#39;s in the data</span>
<span class="n">data</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Day-of-Week</th>
      <th>Condition</th>
      <th>Hospitalized</th>
      <th>Antibiotics</th>
    </tr>
    <tr>
      <th>Patient ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9394</th>
      <td>Friday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>898</th>
      <td>Sunday</td>
      <td>Allergic Reaction</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>2398</th>
      <td>Saturday</td>
      <td>Entangled Antennas</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>5906</th>
      <td>Saturday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2343</th>
      <td>Monday</td>
      <td>High Fever</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <th>8225</th>
      <td>Thursday</td>
      <td>High Fever</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <th>5506</th>
      <td>Tuesday</td>
      <td>High Fever</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>6451</th>
      <td>Thursday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2670</th>
      <td>Sunday</td>
      <td>Intoxication</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>3497</th>
      <td>Tuesday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1087</th>
      <td>Monday</td>
      <td>High Fever</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1819</th>
      <td>Tuesday</td>
      <td>High Fever</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2308</th>
      <td>Tuesday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>6084</th>
      <td>Monday</td>
      <td>High Fever</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>3724</th>
      <td>Tuesday</td>
      <td>Allergic Reaction</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Next, we introduce a helper function, <code class="docutils literal notranslate"><span class="pre">pfml.mle</span></code>, for performing the MLE. This function takes in:</p>
<ul class="simple">
<li><p>A <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> model.</p></li>
<li><p>An optimizer—this is what will do the maximization. We’ll cover optimization at a later chapter. For now, you can just treat them as black boxes.</p></li>
<li><p>A random generator key, used by the optimizer.</p></li>
<li><p>The number of iterations we’d like the optimizer to run for (this optimization algorithm is iterative).</p></li>
<li><p>Finally, we pass in the arguments of the model. In this case, we pass in <code class="docutils literal notranslate"><span class="pre">N,</span> <span class="pre">d=d,</span> <span class="pre">i=i</span></code>. For our model <code class="docutils literal notranslate"><span class="pre">N</span></code> is a require argument (for the number of elements in <code class="docutils literal notranslate"><span class="pre">numpyro.plate</span></code>). You’ll notice that in our model, <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">i</span></code> are both optional. We pass them in here to give the MLE the data (without them, how can we maximize the probability of the data?).</p></li>
</ul>
<p>Putting all of this together, we get:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get data from the data frame. </span>
<span class="c1"># Use our helper function, convert_day_of_week_to_int, to convert the days of the week to ints</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">convert_day_of_week_to_int</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Day-of-Week&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Condition&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Intoxication&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="c1"># Number of data points</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="c1"># Number of iterations we want the optimizer to take when maximizing the likelihood of the data</span>
<span class="n">NUM_ITERATIONS</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Pick the size of update to the model&#39;s parameter during optimization</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># Define an optimizer; here we chose the &quot;Adam&quot; algorithm</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>

<span class="c1"># Pick a random generator seed for the optimizer</span>
<span class="n">key_optimizer</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Perform MLE!</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pfml</span><span class="o">.</span><span class="n">mle</span><span class="p">(</span>
    <span class="n">model_of_intoxication_and_day</span><span class="p">,</span> 
    <span class="n">optimizer</span><span class="p">,</span> 
    <span class="n">key_optimizer</span><span class="p">,</span>
    <span class="n">NUM_ITERATIONS</span><span class="p">,</span>
    <span class="n">N</span><span class="p">,</span> 
    <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> 
    <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/1000 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 1/1000 [00:00&lt;08:35,  1.94it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 28%|██▊       | 281/1000 [00:00&lt;00:01, 608.28it/s, init loss: 26390.5733, avg. loss [201-250]: 23521.5939]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 58%|█████▊    | 577/1000 [00:00&lt;00:00, 1163.31it/s, init loss: 26390.5733, avg. loss [501-550]: 23338.8734]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 85%|████████▌ | 854/1000 [00:00&lt;00:00, 1567.52it/s, init loss: 26390.5733, avg. loss [801-850]: 23335.5744]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 1000/1000 [00:00&lt;00:00, 1149.23it/s, init loss: 26390.5733, avg. loss [951-1000]: 23335.5544]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done.
</pre></div>
</div>
</div>
</div>
<p>The object returned to us by <code class="docutils literal notranslate"><span class="pre">pfml.mle</span></code> contains several useful components:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">result.model_mle</span></code> is the <em>fitted</em> model. We’ll need this to sample from the <em>fitted</em> model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">result.parameters_mle</span></code> are the parameters of the fitted model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">result.log_likelihood</span></code> is the joint data log-likelihood for every iteration of training. This is helpful for visualizing the convergence of the optimizer.</p></li>
</ul>
<p><strong>Visualizing the Convergence of the MLE:</strong> We can plot the model’s log-likelihood with each iteration of the optimizer to see whether (1) the log-likelihood is increasing, as it should, and (2) whether the optimization converged (i.e. do we think there’s no more room to improve).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">NUM_ITERATIONS</span><span class="p">),</span> <span class="n">result</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Optimization Step&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Log Likelihood&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Convergence of MLE&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7e161bed37f698193f822106201c9e7272e6cf0319ea61896d4cd871bb8647fd.png" src="_images/7e161bed37f698193f822106201c9e7272e6cf0319ea61896d4cd871bb8647fd.png" />
</div>
</div>
<p><strong>Visualizing the Model’s Parameters:</strong> The learned model’s parameters, <span class="math notranslate nohighlight">\(\pi\)</span> and <span class="math notranslate nohighlight">\(\rho\)</span>, can be accessed as below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result</span><span class="o">.</span><span class="n">parameters_mle</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;pi&#39;: Array([0.1987, 0.1529, 0.1399, 0.1419, 0.136 , 0.113 , 0.1176], dtype=float64),
 &#39;rho&#39;: Array([0.09473922, 0.09301582, 0.09448023, 0.10785802, 0.10519358,
        0.4079646 , 0.41496599], dtype=float64)}
</pre></div>
</div>
</div>
</div>
<p>We can then visualize these learned probabilities to see if they match our observed data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">days_of_week</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Monday&#39;</span><span class="p">,</span> <span class="s1">&#39;Tuesday&#39;</span><span class="p">,</span> <span class="s1">&#39;Wednesday&#39;</span><span class="p">,</span> <span class="s1">&#39;Thursday&#39;</span><span class="p">,</span> <span class="s1">&#39;Friday&#39;</span><span class="p">,</span> <span class="s1">&#39;Saturday&#39;</span><span class="p">,</span> <span class="s1">&#39;Sunday&#39;</span><span class="p">]</span>

<span class="n">marginal_probabilities_from_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">conditional_probabilities_from_data</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Iterate over the days of the week</span>
<span class="k">for</span> <span class="n">day</span> <span class="ow">in</span> <span class="n">days_of_week</span><span class="p">:</span>
    <span class="c1"># Select all patients that came in on the specific day of the week</span>
    <span class="n">patients_on_day</span> <span class="o">=</span> <span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Day-of-Week&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">day</span><span class="p">)]</span>

    <span class="c1"># Of the selected patients, further select patients with intoxication</span>
    <span class="n">patient_intoxicated_on_day</span> <span class="o">=</span> <span class="n">patients_on_day</span><span class="p">[</span><span class="n">patients_on_day</span><span class="p">[</span><span class="s1">&#39;Condition&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Intoxication&#39;</span><span class="p">]</span>

    <span class="c1"># Compute the portion of patients with intoxication on this day</span>
    <span class="n">portion_intoxicated_on_day</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">patient_intoxicated_on_day</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">patients_on_day</span><span class="p">))</span>

    <span class="c1"># Compute the portion of patients arriving on this day</span>
    <span class="n">portion_arriving_on_day</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">patients_on_day</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    
    <span class="n">marginal_probabilities_from_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">portion_arriving_on_day</span><span class="p">)</span>
    <span class="n">conditional_probabilities_from_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">portion_intoxicated_on_day</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot marginal</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">width</span><span class="p">,</span> <span class="n">marginal_probabilities_from_data</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">width</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">parameters_mle</span><span class="p">[</span><span class="s1">&#39;pi&#39;</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;MLE for $\pi$&#39;</span><span class="p">)</span>

<span class="c1"># Add axis labels and titles</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">7</span><span class="p">),</span> <span class="n">days_of_week</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Day of Week&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability of Day-of-Week&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Marginal Probability of Patient Arriving on Each Day&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/60da6573e06cd5dd2eba20b2b0fe9d9c328c80961262becfd412a71eb313590f.png" src="_images/60da6573e06cd5dd2eba20b2b0fe9d9c328c80961262becfd412a71eb313590f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot conditional</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">width</span><span class="p">,</span> <span class="n">conditional_probabilities_from_data</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">width</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">parameters_mle</span><span class="p">[</span><span class="s1">&#39;rho&#39;</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;MLE for $\rho$&#39;</span><span class="p">)</span>

<span class="c1"># Add axis labels and titles</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">7</span><span class="p">),</span> <span class="n">days_of_week</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Day of Week&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability of Intoxication&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Conditional Probability of Intoxication Given Day&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0977b069c1ca36d1f29b5927cdd311bc6269b604136e714acc9d77cd3bc34078.png" src="_images/0977b069c1ca36d1f29b5927cdd311bc6269b604136e714acc9d77cd3bc34078.png" />
</div>
</div>
<p><strong>Sampling from the Fitted Model:</strong> We can sample from the fitted model using the code below. Notice that, as with sampling before, we pass in <code class="docutils literal notranslate"><span class="pre">None</span></code> for the data (i.e. <code class="docutils literal notranslate"><span class="pre">d=None,</span> <span class="pre">i=None</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">20</span> <span class="c1"># Number of samples to generate</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Random generator key to use</span>

<span class="n">pfml</span><span class="o">.</span><span class="n">sample_generative_process</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">model_mle</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;pi&#39;: Array([0.1987, 0.1529, 0.1399, 0.1419, 0.136 , 0.113 , 0.1176], dtype=float64),
 &#39;rho&#39;: Array([0.09473922, 0.09301582, 0.09448023, 0.10785802, 0.10519358,
        0.4079646 , 0.41496599], dtype=float64),
 &#39;d&#39;: Array([0, 6, 4, 3, 3, 4, 5, 6, 0, 5, 1, 4, 1, 4, 3, 2, 5, 4, 6, 6], dtype=int64),
 &#39;i&#39;: Array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)}
</pre></div>
</div>
</div>
</div>
<div class="admonition-exercise-perform-the-mle-on-the-ihh-er-model admonition">
<p class="admonition-title">Exercise: Perform the MLE on the IHH ER model</p>
<p><strong>Part 1:</strong> You now have all of the tools necessary (1) write the data generating process for the IHH ER model in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>, and (2) perform the MLE on the <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> model. We recommend working on parts (1) and (2) together, incrementally building the model. Specifically, we recommend adding distributions in the following order:</p>
<p>a. <span class="math notranslate nohighlight">\(p_D\)</span></p>
<p>b. <span class="math notranslate nohighlight">\(p_{C | D}\)</span></p>
<p>c. <span class="math notranslate nohighlight">\(p_{H | C}\)</span></p>
<p>d. <span class="math notranslate nohighlight">\(p_{A | C, H}\)</span></p>
<p>Please use the following function signature for your model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">model_of_ihh_er</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">pass</span>
</pre></div>
</div>
<p>Note: Don’t forget to visualize your convergence plot to make sure your training converged!</p>
<p><strong>Part 2:</strong> Compare the parameters of each distribution (marginal and conditional) in the learned model with the distributions observed in the data (just like we did above). Do they match?</p>
<p><strong>Part 3:</strong> Notice that so far, we’ve relied on a fairly large data-set. But what how good is our learned model if we have a much smaller data set, as is common in many healthcare scenarios? To test this, you can fit your model to a subsample of the data and compare the learned parameters with the distributions observed in the non-subsampled data. That is:</p>
<p>a. We pretend we only observe a small subsample of the data: <code class="docutils literal notranslate"><span class="pre">subsample</span> <span class="pre">=</span> <span class="pre">data.sample(50,</span> <span class="pre">random_state=0)</span></code>.</p>
<p>b. We fit the model to <code class="docutils literal notranslate"><span class="pre">subsample</span></code>.</p>
<p>c. We then compare the parameters of the learned model to those observed in <code class="docutils literal notranslate"><span class="pre">data</span></code>.</p>
<p>d. Compare your results to those from Part (2). What do you notice?</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="mle-theory.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">8. </span>Maximum Likelihood: Theory</p>
      </div>
    </a>
    <a class="right-next"
       href="optimization.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">10. </span>Optimization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-generating-process">9.1. The Data Generating Process</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-the-generative-process-or-model-in-numpyro">9.2. Implementing the “Generative Process” (or Model) in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <footer>
  <div class="flex-shrink-0 container">
    <div class="row align-items-center">
      <div class="col-8">

        <p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">Probabilistic Foundations of Machine Learning</span> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://yanivyacoby.github.io/" target="_blank">Yaniv Yacoby</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1" alt=""></a></p>

      </div>      
      <div class="col-4">
        <img src="_static/img/wc-logo-blue.png" alt="Wellesley College Logo" class="only-light" style="max-width: 120px; float: right; display: block;"/>
        <img src="_static/img/wc-logo-white.png" alt="Wellesley College Logo" class="only-dark" style="max-width: 120px; float: right; display: block;"/>
      </div>
    </div>    
  </div>  
</footer>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>