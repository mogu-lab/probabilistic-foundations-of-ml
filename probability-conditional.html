
<!DOCTYPE html>


<html lang="en" data-content_root="./" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5. Conditional Probability (Discrete) &#8212; Probabilistic Foundations of Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/css/course_schedule.css?v=244d4a68" />
    <link rel="stylesheet" type="text/css" href="_static/css/main.css?v=19873a65" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'probability-conditional';</script>
    <link rel="canonical" href="https://mogu-lab.github.io/probabilistic-foundations-of-ml/probability-conditional.html" />
    <link rel="icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. Joint Probability (Discrete)" href="probability-joint.html" />
    <link rel="prev" title="4. Probability (Discrete)" href="probability-discrete.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Probabilistic Foundations of Machine Learning - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Probabilistic Foundations of Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Probabilistic Foundations of ML
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. Probabilistic ML: What is it? Why use it?</a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-basics.html">2. Introduction to Vectorization</a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-advanced.html">3. Advanced Vectorization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Directed Graphical Models</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="probability-discrete.html">4. Probability (Discrete)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5. Conditional Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-joint.html">6. Joint Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-data.html">7. The Ethics of Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frequentist Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mle-theory.html">8. Maximum Likelihood: Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="mle-code.html">9. Maximum Likelihood: Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html">10. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-continuous.html">11. Probability (Continuous)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-learning-from-data.html">12. The Ethics of Learning from Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Predictive Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="regression.html">13. Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification.html">14. Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural-networks.html">15. Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-selection.html">16. Model Selection &amp; Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-predictive-models.html">17. The Ethics of Predictive Models in Sociotechnical Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generative Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="gmms.html">18. Gaussian Mixture Models (Clustering)</a></li>
<li class="toctree-l1"><a class="reference internal" href="factor-analysis.html">19. Factor Analysis (Dimensionality Reduction)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-generative-models.html">20. The Ethics of Generative Models in Sociotechnical Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="priors-and-posteriors.html">21. Priors and Posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="posterior-predictives.html">22. Posterior Predictives</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethics-of-uncertainty-and-interpretability.html">23. The Ethics of Uncertainty and Interpretability in Human-AI Systems</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Synthesis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ethics-of-ml.html">24. The Ethics of Machine Learning: A View from History</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/probability-conditional.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Conditional Probability (Discrete)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology-and-notation">5.1. Terminology and Notation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-familiar-with-distributions-in-numpyro">5.2. Getting Familiar with Distributions in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-hallucinations-in-large-language-models-llms">5.3. Understanding Hallucinations in Large Language Models (LLMs)</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="conditional-probability-discrete">
<h1><span class="section-number">5. </span>Conditional Probability (Discrete)<a class="headerlink" href="#conditional-probability-discrete" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import some helper functions (please ignore this!)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">utils</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span> 
</pre></div>
</div>
</div>
</div>
<p><strong>Context:</strong> You’ve already spent some time conducting a preliminary exploratory data analysis (EDA) of IHH’s ER data. You noticed that considering variables separately can result in misleading information. As such, today you will continue your EDA, this time also considering the <em>relationship between variables</em>. For example, you may want to know:</p>
<ul class="simple">
<li><p>Are there certain conditions that are more likely to occur on certain days?</p></li>
<li><p>What makes a patient likely to need hospitalization?</p></li>
</ul>
<p><strong>Challenge:</strong> So far, however, we’ve only seen ways of characterizing the variability/stochasticity of a univariate random phenomenon independently of other variables. So how can we consider the relationship between variables? Answer: conditional probability.</p>
<p><strong>Outline:</strong></p>
<ol class="arabic simple">
<li><p>Introduce and practice the concepts, terminology, and notation behind discrete conditional probability distributions (leaving continuous distributions to a later time).</p></li>
<li><p>Answer the above questions using this new toolset.</p></li>
</ol>
<p>Before getting started, let’s load in our IHH ER data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import a bunch of libraries we&#39;ll be using below</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pylab</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">D</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>

<span class="c1"># Load the data into a pandas dataframe</span>
<span class="n">csv_fname</span> <span class="o">=</span> <span class="s1">&#39;data/IHH-ER.csv&#39;</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_fname</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;Patient ID&#39;</span><span class="p">)</span>

<span class="c1"># Print a random sample of patients, just to see what&#39;s in the data</span>
<span class="n">data</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Day-of-Week</th>
      <th>Condition</th>
      <th>Hospitalized</th>
      <th>Antibiotics</th>
    </tr>
    <tr>
      <th>Patient ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9394</th>
      <td>Friday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>898</th>
      <td>Sunday</td>
      <td>Allergic Reaction</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>2398</th>
      <td>Saturday</td>
      <td>Entangled Antennas</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>5906</th>
      <td>Saturday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2343</th>
      <td>Monday</td>
      <td>High Fever</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <th>8225</th>
      <td>Thursday</td>
      <td>High Fever</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <th>5506</th>
      <td>Tuesday</td>
      <td>High Fever</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>6451</th>
      <td>Thursday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2670</th>
      <td>Sunday</td>
      <td>Intoxication</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>3497</th>
      <td>Tuesday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1087</th>
      <td>Monday</td>
      <td>High Fever</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1819</th>
      <td>Tuesday</td>
      <td>High Fever</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2308</th>
      <td>Tuesday</td>
      <td>Allergic Reaction</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>6084</th>
      <td>Monday</td>
      <td>High Fever</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <th>3724</th>
      <td>Tuesday</td>
      <td>Allergic Reaction</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<section id="terminology-and-notation">
<h2><span class="section-number">5.1. </span>Terminology and Notation<a class="headerlink" href="#terminology-and-notation" title="Link to this heading">#</a></h2>
<p>As with (non-conditional) discrete probability, the statistical language—terminology and notation—we introduce here will allow us to precisely specify to a computer how to model our data. In the future, we will translate statements in this language directly into code that a computer can run.</p>
<p><strong>Concept.</strong> Conditional probabilities allow us to ask questions of the form, “given that <span class="math notranslate nohighlight">\(A\)</span> is true, what’s the probability of <span class="math notranslate nohighlight">\(B\)</span>?”. Although simple, this idea is actually quite powerful; all <em>predictive models</em> you may have heard of (e.g. regression, classification, etc.) are formulated using <em>conditional distributions</em>. To see what we mean, let’s start with an example.</p>
<p><strong>Example.</strong> Suppose you’re working at the IHH ER, and you want to <em>predict</em> what is the probability that the next patient comes in with <code class="docutils literal notranslate"><span class="pre">Condition</span> <span class="pre">==</span> <span class="pre">&quot;Intoxication&quot;</span></code>. Given previously collected data, you can estimate this probability by counting the number of patients for which <code class="docutils literal notranslate"><span class="pre">Condition</span> <span class="pre">==</span> <span class="pre">&quot;Intoxication&quot;</span></code> and dividing by the total number of patients:</p>
<div class="amsmath math notranslate nohighlight" id="equation-e65321ad-f388-49b2-b02b-62a76e0106da">
<span class="eqno">(5.1)<a class="headerlink" href="#equation-e65321ad-f388-49b2-b02b-62a76e0106da" title="Permalink to this equation">#</a></span>\[\begin{align}
\text{Probability of intoxication} = \frac{\text{Number of patients with intoxication}}{\text{Total number of patients}}
\end{align}\]</div>
<p>We’ll call this probability the “naive predictor.” Now, let’s compute this naive predictor on our IHH ER data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_intoxicated</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Condition&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Intoxication&#39;</span><span class="p">])</span>
<span class="n">num_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">naive_probability_of_intoxication</span> <span class="o">=</span> <span class="n">num_intoxicated</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_total</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Portion with Intoxication (Naive Predictor) =&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">naive_probability_of_intoxication</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Portion with Intoxication (Naive Predictor) = 0.171
</pre></div>
</div>
</div>
</div>
<p>However, you also know that even in far reaches of the outer universe, beings work Mondays through Fridays, taking Saturdays and Sundays off. Therefore, you suspect intoxication may be more likely to occur on weekends. You decide to check whether your intuition is true here. If it’s true, will you improve your ability to predict how likely the next patient is to come with intoxication?</p>
<p>We can modify the naive predictor above as follows to condition on the day of the week:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3856616c-33f3-426b-8ee0-dfa1a747170c">
<span class="eqno">(5.2)<a class="headerlink" href="#equation-3856616c-33f3-426b-8ee0-dfa1a747170c" title="Permalink to this equation">#</a></span>\[\begin{align}
\text{Probability of intoxication given day $d$} = \frac{\text{Number of patients with intoxication on day $d$}}{\text{Total number of patients on day $d$}}
\end{align}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">days_of_week</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Monday&#39;</span><span class="p">,</span> <span class="s1">&#39;Tuesday&#39;</span><span class="p">,</span> <span class="s1">&#39;Wednesday&#39;</span><span class="p">,</span> <span class="s1">&#39;Thursday&#39;</span><span class="p">,</span> <span class="s1">&#39;Friday&#39;</span><span class="p">,</span> <span class="s1">&#39;Saturday&#39;</span><span class="p">,</span> <span class="s1">&#39;Sunday&#39;</span><span class="p">]</span>

<span class="n">probabilities</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Iterate over the days of the week</span>
<span class="k">for</span> <span class="n">day</span> <span class="ow">in</span> <span class="n">days_of_week</span><span class="p">:</span>
    <span class="c1"># Select all patients that came in on the specific day of the week</span>
    <span class="n">patients_on_day</span> <span class="o">=</span> <span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Day-of-Week&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">day</span><span class="p">)]</span>

    <span class="c1"># Of the selected patients, further select patients with intoxication</span>
    <span class="n">patient_intoxicated_on_day</span> <span class="o">=</span> <span class="n">patients_on_day</span><span class="p">[</span><span class="n">patients_on_day</span><span class="p">[</span><span class="s1">&#39;Condition&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Intoxication&#39;</span><span class="p">]</span>

    <span class="c1"># Compute the portion of patients with intoxication on this day</span>
    <span class="n">portion_intoxicated_on_day</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">patient_intoxicated_on_day</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">patients_on_day</span><span class="p">))</span>

    <span class="n">probabilities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">portion_intoxicated_on_day</span><span class="p">)</span>

<span class="c1"># Plot!</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">days_of_week</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Conditional Predictor&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">naive_probability_of_intoxication</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Naive Predictor&#39;</span><span class="p">)</span>

<span class="c1"># Add axis labels and titles</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Day of Week&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability of Intoxication&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Conditional Probability of Intoxication Given Day at the IHH ER&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6a62be996af3c868857561035ed5a9a2d61dc1369316c721ad10fdd6e7775cb6.png" src="_images/6a62be996af3c868857561035ed5a9a2d61dc1369316c721ad10fdd6e7775cb6.png" />
</div>
</div>
<p>As you can see, the probability of a patient arriving with intoxication changes <em>significantly</em> from the naive predictor (above) if we consider the day of the week. Specifically, the above plot shows us that our naive predictor</p>
<ol class="arabic simple">
<li><p>significantly <em>over-estimates</em> the probability of intoxication on weekdays, and</p></li>
<li><p>significantly <em>under-estimates</em> the probability of intoxication on weekends.</p></li>
</ol>
<p>Using a conditional distribution, we can leverage additional information (day of the week) to improve our prediction!</p>
<p><strong>Definition and Notation:</strong> A conditional probability is a probability distribution that changes as a function of another random variable.</p>
<blockquote>
<div><p>Continuing with the above example,</p>
<ul class="simple">
<li><p>Let <span class="math notranslate nohighlight">\(D\)</span> denote the day of the week.</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(I\)</span> denote whether the patient arrives with intoxication.</p></li>
</ul>
<p>Here, <span class="math notranslate nohighlight">\(p_I(\cdot)\)</span> describes the (non-conditional) probability that a patient arrives with intoxication. It represents our <em>naive</em>, inaccurate prediction. In contrast, <span class="math notranslate nohighlight">\(p_{I | D}(\cdot | d)\)</span> describes the <em>conditional</em> probability of “intoxication given the day”—the probability of intoxication changes from weekdays to weekends. In this notation, what comes on the right side of the vertical line is the “condition” (here, <span class="math notranslate nohighlight">\(D = d\)</span>).</p>
</div></blockquote>
<p><strong>Sample Space or Support:</strong> Since a discrete conditional distribution is still a discrete distribution, all notation/terminology from discrete probability still holds.</p>
<blockquote>
<div><p>For our running example, the sample space is that of variable to the left of the line, <span class="math notranslate nohighlight">\(I\)</span>. That is, the sample space of <span class="math notranslate nohighlight">\(p_{I | D}(\cdot | d)\)</span> is <span class="math notranslate nohighlight">\(I \in \{ 0, 1 \}\)</span> (with 1 means intoxicated and 0 means not intoxicated).</p>
</div></blockquote>
<p><strong>Probability Mass Function (PMF):</strong> The PMF is, again, that of the variable to the left of the vertical line. What makes a conditional probability different from a non-conditional distribution, however, is that the parameter of the distribution is now a <em>function of the condition</em>.</p>
<blockquote>
<div><p>In our example, the PMF is that of a Bernoulli random variable (since <span class="math notranslate nohighlight">\(I\)</span> can only take on two values). Since it’s a <em>conditional</em> distribution, it’s parameter depends on the condition (the day <span class="math notranslate nohighlight">\(D = d\)</span>). We can write this as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b9f93909-ae41-4519-b46c-fc7df73e2a76">
<span class="eqno">(5.3)<a class="headerlink" href="#equation-b9f93909-ae41-4519-b46c-fc7df73e2a76" title="Permalink to this equation">#</a></span>\[\begin{align}
p_{I | D}(\cdot | d) = \mathrm{Ber}(\rho(d)),
\end{align}\]</div>
<p>where</p>
<div class="amsmath math notranslate nohighlight" id="equation-3b58589a-820e-4561-bbfc-603a01060811">
<span class="eqno">(5.4)<a class="headerlink" href="#equation-3b58589a-820e-4561-bbfc-603a01060811" title="Permalink to this equation">#</a></span>\[\begin{align}
p_{I | D}(i | d) = \underbrace{\rho(d)^{i} \cdot \left(1 - \rho(d) \right)^{1 - i}}_{\text{Bernoulli PMF (see Wikipedia)}},
\end{align}\]</div>
<p>and where</p>
<div class="amsmath math notranslate nohighlight" id="equation-8e13dbd2-f577-4fca-bfe9-b52ebd74d06d">
<span class="eqno">(5.5)<a class="headerlink" href="#equation-8e13dbd2-f577-4fca-bfe9-b52ebd74d06d" title="Permalink to this equation">#</a></span>\[\begin{align} \rho(d) &amp;= \begin{cases}
0.1 &amp; \text{if $d$ is weekday} \\
0.4 &amp; \text{if $d$ is weekend} 
\end{cases} 
\end{align}\]</div>
<p>In a sense, a conditional probability is the “if/else-expression of probability.”</p>
</div></blockquote>
<p><strong>Independent, Identically Distributed (i.i.d):</strong> Just as before, a variable can be sampled i.i.d from a distribution.</p>
<blockquote>
<div><p>Given <span class="math notranslate nohighlight">\(D = d\)</span>, we write that <span class="math notranslate nohighlight">\(I\)</span> is sampled i.i.d from the conditional as follows: <span class="math notranslate nohighlight">\(I | d \sim p_{I | D}(\cdot | d)\)</span>. This means that, given the day (e.g. <span class="math notranslate nohighlight">\(d = \mathrm{Monday}\)</span>), observing one patient with intoxication tells us nothing about the probability of observing another patient with intoxication. Note that without conditioning on the day, this is not true: observing many patients with intoxication could tell us that the current day is on a weekend, which means the probability of intoxication is higher overall.</p>
</div></blockquote>
<p><strong>Summary of Notation:</strong></p>
<ul class="simple">
<li><p>Let <span class="math notranslate nohighlight">\(R\)</span> and <span class="math notranslate nohighlight">\(C\)</span> denote two RVs.</p></li>
<li><p><span class="math notranslate nohighlight">\(R | c\)</span> is then an RV describing “<span class="math notranslate nohighlight">\(R\)</span> given <span class="math notranslate nohighlight">\(C = c\)</span>”.</p></li>
<li><p><span class="math notranslate nohighlight">\(p_{R | C}(r | c)\)</span> is the evaluation of the conditional PMF at <span class="math notranslate nohighlight">\(r\)</span>: i.e. given that <span class="math notranslate nohighlight">\(C = c\)</span>, what’s the probability that <span class="math notranslate nohighlight">\(R = r\)</span>?</p></li>
<li><p><span class="math notranslate nohighlight">\(p_{R | C}(\cdot | c)\)</span> is the conditional PMF of <span class="math notranslate nohighlight">\(R | c\)</span>. The dot represents the fact that we’re representing the <em>whole</em> distribution—we haven’t yet ask about the probability of <span class="math notranslate nohighlight">\(R = r\)</span> as above.</p></li>
<li><p><span class="math notranslate nohighlight">\(R | c \sim p_{R | C}(\cdot | c)\)</span> denotes that <span class="math notranslate nohighlight">\(R | c\)</span> is sampled i.i.d. from <span class="math notranslate nohighlight">\(p_{R | C}(\cdot | c)\)</span></p></li>
</ul>
<div class="admonition-exercise-fit-conditional-distributions-by-hand admonition">
<p class="admonition-title">Exercise: Fit conditional distributions by hand</p>
<p>Let us define the following RVs:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D\)</span>: Day-of-Week</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span>: Condition</p></li>
<li><p><span class="math notranslate nohighlight">\(H\)</span>: Hospitalized</p></li>
<li><p><span class="math notranslate nohighlight">\(A\)</span>: Antibiotics</p></li>
</ul>
<p>Our goal is to learn the distributions of the following conditional RVs:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(C | D\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(H | C\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(A | C, H\)</span> (here, we condition on <em>two</em> RVs)</p></li>
</ol>
<p>Each one of these conditional distributions represents a <em>predictive model</em>. For example, (1) says “given that the day is <span class="math notranslate nohighlight">\(D = d\)</span>, predict how likely is a patient to arrive with condition <span class="math notranslate nohighlight">\(C =c\)</span>”?</p>
<p><strong>Part 1:</strong> By exploring the data (as we did in the above example for “intoxication given day”), empirically estimate each conditional distribution above. When we say, “estimate the conditional distribution,” we mean you estimate the distribution for every condition; for example, for <span class="math notranslate nohighlight">\(C | D\)</span>, we want you to empirically estimate <span class="math notranslate nohighlight">\(C | D\)</span> for <em>every</em> <span class="math notranslate nohighlight">\(D = d\)</span>. Use the notation we introduced to write your answer. Don’t forget to show your work with all the plots you generate!</p>
<p><strong>Part 2:</strong> Compare each conditional distribution with its corresponding non-conditional version (these are called <em>marginals</em>) from before. What differences do you notice? How can the differences mislead the IHH ER?</p>
</div>
</section>
<section id="getting-familiar-with-distributions-in-numpyro">
<h2><span class="section-number">5.2. </span>Getting Familiar with Distributions in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code><a class="headerlink" href="#getting-familiar-with-distributions-in-numpyro" title="Link to this heading">#</a></h2>
<p>Now that we’ve learned some conditional distributions by hand, we’ll introduce the framework we’ll use to implement our ML models: <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>. And specifically, we’ll introduce one of the main building blocks in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>: distributions.</p>
<p><strong>What is <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>?</strong> <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> is a “Probabilistic Programming Language” based in <code class="docutils literal notranslate"><span class="pre">Jax</span></code>. It provides an interface for (nearly) direct translation of the stats/math we wrote above into code that we can use to fit to data, make predictions, and more. This will allow us to focus on the conceptual ideas behind probabilistic ML.</p>
<p><strong>Instantiating Distributions in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>.</strong> <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> comes with many distributions already implemented. For a complete list of all available discrete distributions, check out the <a class="reference external" href="https://num.pyro.ai/en/stable/distributions.html#discrete-distributions" rel="noreferrer" target="_blank">this part of the documentation</a>. So why use <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> instead of implementing the distributions on our own? It’s easy to write subtle bugs that are hard to catch when implementing mathematical formulas in code. Also, using <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>’s distributions will help us highlight the overall <em>logic</em> of the code, instead of getting bogged down by the mathematical details.</p>
<p>Distributions in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> have several notable properties and methods we will rely on. Let’s explore them together. First, we import the necessary components of <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.random</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jrandom</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">D</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s instantiate the simplest discrete distribution we know, the Bernoulli distribution, to describe the naive predictor from earlier.</p>
<div class="amsmath math notranslate nohighlight" id="equation-31a4cb8c-0de2-45ad-bbb7-848f4eacf1e3">
<span class="eqno">(5.6)<a class="headerlink" href="#equation-31a4cb8c-0de2-45ad-bbb7-848f4eacf1e3" title="Permalink to this equation">#</a></span>\[\begin{align}
p_I(i) &amp;= \mathrm{Ber}(\rho) = \rho^i \cdot (1 - \rho)^{1 - i}
\end{align}\]</div>
<p>Recall that a Bernoulli distribution takes in just one parameter, <span class="math notranslate nohighlight">\(\rho \in [0, 1]\)</span>, which determines the probability of sampling <span class="math notranslate nohighlight">\(I = 1\)</span> vs. <span class="math notranslate nohighlight">\(I = 0\)</span> (or Yes vs. No). Here let’s instantiate the Bernoulli distribution with <span class="math notranslate nohighlight">\(\rho = 0.2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rho</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">p_I</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">rho</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That’s it!</p>
<p><strong>Evaluating the PMF of <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> Distributions.</strong> Now, if we want to evaluate the PMF, <span class="math notranslate nohighlight">\(p_I(i)\)</span>, we can use <code class="docutils literal notranslate"><span class="pre">log_prob</span></code> method as follows (note that this returns the <em>log</em> of the PMF, so we’ll have to exponentiate the result):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_p_I_eq_1</span> <span class="o">=</span> <span class="n">p_I</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Probability of sampling a 1:&#39;</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p_I_eq_1</span><span class="p">))</span>

<span class="n">log_p_I_eq_0</span> <span class="o">=</span> <span class="n">p_I</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Probability of sampling a 0:&#39;</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p_I_eq_0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Probability of sampling a 1: 0.2
Probability of sampling a 0: 0.8
</pre></div>
</div>
</div>
</div>
<p><strong>Sampling from <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> Distributions.</strong> <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> distributions all have a <code class="docutils literal notranslate"><span class="pre">sample</span></code> method which can be used to draw samples. It takes in two arguments:</p>
<ol class="arabic simple">
<li><p>A random number generator “key,” which controls the randomness of the sample.</p></li>
<li><p>A shape, describing the number of i.i.d samples you want to draw.</p></li>
</ol>
<p>Let’s give it a go:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,)</span> <span class="c1"># Shape of i.i.d samples we wish to draw </span>

<span class="n">key1</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Create a random number generator key</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;First batch drawn with key1: &#39;</span><span class="p">,</span> <span class="n">p_I</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key1</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Second batch drawn with key1:&#39;</span><span class="p">,</span> <span class="n">p_I</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key1</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>

<span class="n">key2</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Create a random number generator key</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Third batch drawn with key2: &#39;</span><span class="p">,</span> <span class="n">p_I</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key2</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First batch drawn with key1:  [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]
Second batch drawn with key1: [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]
Third batch drawn with key2:  [1 0 0 0 0 0 0 0 0 1 1 1 0 0 0]
</pre></div>
</div>
</div>
</div>
<p>Notice in the above code, when using the same key twice (or the same <code class="docutils literal notranslate"><span class="pre">seed</span></code>), we get the <em>exact same batch of samples</em>. This is both a blessing and a curse. It’s a blessing because this allows us to precisely control the randomness of our ML code. This will prove crucial for debugging later on. However, it can also be a curse if we accidentally use the same key in a place where we need two different sources of randomness.</p>
<p><strong>Best Practice: How to Manage Your Keys.</strong> We will follow two rules of thumb:</p>
<ol class="arabic simple">
<li><p>Make only ONE CALL to <code class="docutils literal notranslate"><span class="pre">jrandom.PRNGKey</span></code> in your entire code.</p></li>
<li><p>Never use the same key twice.</p></li>
</ol>
<p>But if we’re restricting ourselves to only creating one key with <code class="docutils literal notranslate"><span class="pre">jrandom.PRNGKey</span></code>, how can we possibly call <code class="docutils literal notranslate"><span class="pre">sample</span></code> multiple times with different keys? <code class="docutils literal notranslate"><span class="pre">Jax</span></code> allows us to take a random key and “split” it into multiple different keys, each of which can be used for different purposes. We note that “splitting” is a little bit misleading of a term—we don’t start with one key, and then after splitting get a “fraction” of a key; instead, we start with one key, and then deterministically derive other keys from it. This means we can create ONE KEY to control the randomness of our entire code. We can then split this key into multiple keys as needed. Here’s how we can do this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create ONE KEY to be used by your ENTIRE CODE</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Whenever you need to use the key for multiple purposes, split it into parts:</span>
<span class="n">key_first</span><span class="p">,</span> <span class="n">key_second</span><span class="p">,</span> <span class="n">key_third</span> <span class="o">=</span> <span class="n">jrandom</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> 

<span class="c1"># Use a different key for each need</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;First batch drawn with key_first:  &#39;</span><span class="p">,</span> <span class="n">p_I</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key_first</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Second batch drawn with key_second:&#39;</span><span class="p">,</span> <span class="n">p_I</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key_second</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Third batch drawn with key_third:  &#39;</span><span class="p">,</span> <span class="n">p_I</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">key_third</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First batch drawn with key_first:   [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]
Second batch drawn with key_second: [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]
Third batch drawn with key_third:   [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1]
</pre></div>
</div>
</div>
</div>
<p><strong>Conditional Distributions in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>:</strong> Now that we’ve implemented the naive predictor, let’s implement our better predictor, <span class="math notranslate nohighlight">\(p_{I | D}(i | d)\)</span>. Recall the only difference between this predictor and the naive predictor is that the parameter of the distribution, <span class="math notranslate nohighlight">\(\rho\)</span>, now depends on the day, <span class="math notranslate nohighlight">\(d\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">p_intoxication_given_day</span><span class="p">(</span><span class="n">day</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Assume day is an integer from 0 to 6 (Monday to Sunday)</span>
<span class="sd">    &#39;&#39;&#39;</span>    

    <span class="n">rho_given_d</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">])</span>
    
    <span class="n">p_I_given_d</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">rho_given_d</span><span class="p">[</span><span class="n">day</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">p_I_given_d</span>

<span class="c1"># Example uses</span>
<span class="n">p_I_given_Monday</span> <span class="o">=</span> <span class="n">p_intoxication_given_day</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="n">p_I_given_Saturday</span> <span class="o">=</span> <span class="n">p_intoxication_given_day</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>In the above, <code class="docutils literal notranslate"><span class="pre">p_I_given_Monday</span></code> and <code class="docutils literal notranslate"><span class="pre">p_I_given_Saturday</span></code> are just <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> Bernoulli distributions, so you can use their <code class="docutils literal notranslate"><span class="pre">log_prob</span></code> and <code class="docutils literal notranslate"><span class="pre">sample</span></code> functions just like before.</p>
<div class="admonition-exercise-implement-conditional-distributions admonition">
<p class="admonition-title">Exercise: Implement conditional distributions</p>
<p><strong>Part 1:</strong> Implement each one of the conditional distributions from the previous exercise in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>, following the example of <code class="docutils literal notranslate"><span class="pre">p_intoxication_given_day</span></code> above.</p>
<p>Note: <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code> discrete distributions only work with integers, not strings. For example, instead of using <span class="math notranslate nohighlight">\(d = \text{Monday}\)</span>, you should convert the days of the week into integers from 0 to 6 (Monday to Sunday), and instead use <span class="math notranslate nohighlight">\(d = 0\)</span> for “Monday”. We’ve created two helper functions to help you with this conversion: <code class="docutils literal notranslate"><span class="pre">convert_day_of_week_to_int</span></code> and <code class="docutils literal notranslate"><span class="pre">convert_condition_to_int</span></code>. You can use them as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">convert_day_of_week_to_int(data['Day-of-Week'])</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">convert_condition_to_int(data['Condition'])</span></code></p></li>
</ul>
<p><strong>Part 2:</strong> Verify that your implementation is correct by sampling from each conditional distribution and eye-balling that the samples look correct. When “eye-balling” here, you’re welcome to just print out some samples (no need for making a full plot) and checking that it matches your intuition (e.g. what’s most likely appears most times in your samples). Finally, be sure to follow the best practices above when using a random number generator key.</p>
</div>
</section>
<section id="understanding-hallucinations-in-large-language-models-llms">
<h2><span class="section-number">5.3. </span>Understanding Hallucinations in Large Language Models (LLMs)<a class="headerlink" href="#understanding-hallucinations-in-large-language-models-llms" title="Link to this heading">#</a></h2>
<p>Have you ever noticed that:</p>
<ul class="simple">
<li><p>When typing the <strong>same</strong> question into an LLM, it can answer you in <strong>different</strong> ways?</p></li>
<li><p>That LLMs can answer questions incorrectly (i.e. they “hallucinate”)?</p></li>
</ul>
<p>As an example, on September 10, 2025, we decided to ask ChatGPT what day it was today. After getting its response (which was incorrect), we clicked the little “refresh” button on the bottom right, and it changed its mind, providing us with a second, incorrect response:</p>
<div class="canva-centered-embedding">
  <div class="canva-iframe-container" style="max-width: none;">
    <iframe loading="lazy" class="canva-iframe"
      src="https://www.canva.com/design/DAGymb_Pt8o/pjGc6dKCqEFaMd_BO5c_Qw/view?embed">
    </iframe>
  </div>
</div>
<p>This is because the very strength of LLMs—that they are probabilistic models—is also their shortcoming. What do we mean by that? Let’s define some RVs to help us understand what’s going on under the hood:</p>
<ul class="simple">
<li><p>Let <span class="math notranslate nohighlight">\(I = \)</span> RV denoting the <strong>input</strong> or “prompt” to the LLM.</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(O = \)</span> RV denoting the <strong>output</strong> or “response” of the LLM.</p></li>
</ul>
<p>Using these RVs, you can think of having a chat with an LLM as sampling from the following distributions:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b3a78a99-9df3-4170-9902-521becb53eaf">
<span class="eqno">(5.7)<a class="headerlink" href="#equation-b3a78a99-9df3-4170-9902-521becb53eaf" title="Permalink to this equation">#</a></span>\[\begin{align}
o_1 &amp;\sim p_{O | I}(\cdot | i_1) \\
o_2 &amp;\sim p_{O | I}(\cdot | i_1 + o_1 + i_2) \\
&amp;\vdots
\end{align}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(i_1\)</span> represents your prompt. For example, you may want to ask the LLM “what day is it today?”. Given this prompt, the LLM will sample a sequence of words that seems likely given the data it was trained on. We will call this sequence <span class="math notranslate nohighlight">\(o_1\)</span>. So if the LLM saw a bunch of data that says “What day is it today? Today is June 21”, it is likely to respond with something similar. Of course, since there are likely <em>many responses</em> to this question in the data, it may respond differently. Crucially, note that LLMs are just <strong>auto-completing</strong>—which next word is likely to appear given the previous word we conditioned on. There is <strong>no logic</strong> behind them; that is, they don’t know what day it is actually today! Next, given your first prompt, <span class="math notranslate nohighlight">\(i_1\)</span>, concatenated with the LLM’s response, <span class="math notranslate nohighlight">\(o_1\)</span>, and with your next prompt <span class="math notranslate nohighlight">\(i_2\)</span>, the LLM will continue the conversation, responding with <span class="math notranslate nohighlight">\(o_2\)</span>, and so on.</p>
<div class="admonition-exercise-understanding-hallucinations-in-llms admonition">
<p class="admonition-title">Exercise: Understanding Hallucinations in LLMs</p>
<p>Based on the explanation above, answer:</p>
<ol class="arabic simple">
<li><p>Why can the same prompt result in several different responses from the LLM?</p></li>
<li><p>Why can the LLM answer questions incorrectly? Hint: think of what will it do in response to “2 + 2 = …”.</p></li>
</ol>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="probability-discrete.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Probability (Discrete)</p>
      </div>
    </a>
    <a class="right-next"
       href="probability-joint.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>Joint Probability (Discrete)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology-and-notation">5.1. Terminology and Notation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-familiar-with-distributions-in-numpyro">5.2. Getting Familiar with Distributions in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-hallucinations-in-large-language-models-llms">5.3. Understanding Hallucinations in Large Language Models (LLMs)</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <footer>
  <div class="flex-shrink-0 container">
    <div class="row align-items-center">
      <div class="col-8">

        <p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">Probabilistic Foundations of Machine Learning</span> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://yanivyacoby.github.io/" target="_blank">Yaniv Yacoby</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1" alt=""></a></p>

      </div>      
      <div class="col-4">
        <img src="_static/img/wc-logo-blue.png" alt="Wellesley College Logo" class="only-light" style="max-width: 120px; float: right; display: block;"/>
        <img src="_static/img/wc-logo-white.png" alt="Wellesley College Logo" class="only-dark" style="max-width: 120px; float: right; display: block;"/>
      </div>
    </div>    
  </div>  
</footer>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>