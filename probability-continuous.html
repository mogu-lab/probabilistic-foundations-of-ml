

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>10. Probability (Continuous) &#8212; Probabilistic Foundations of Machine Learning (CS349)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/main.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/course_schedule.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/main.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/course_schedule.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'probability-continuous';</script>
    <link rel="canonical" href="https://mogu-lab.github.io/cs349-fall-2024/probability-continuous.html" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="11. Regression" href="regression.html" />
    <link rel="prev" title="9. Optimization" href="optimization.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Probabilistic Foundations of ML
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Course</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="syllabus.html">Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="schedule.html">Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="help.html">Academic Support &amp; Office Hours</a></li>
<li class="toctree-l1"><a class="reference internal" href="skills-check.html">Skills Check</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. What is Probabilistic ML?</a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-basics.html">2. Vectorization: An Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="vectorization-advanced.html">3. Advanced Vectorization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Directed Graphical Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="probability-discrete.html">4. Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-conditional.html">5. Conditional Probability (Discrete)</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-joint.html">6. Joint Probability (Discrete)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frequentist Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mle-theory.html">7. Maximum Likelihood: Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="mle-code.html">8. Maximum Likelihood: Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html">9. Optimization</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">10. Probability (Continuous)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Predictive Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="regression.html">11. Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification.html">12. Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural-networks.html">13. Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-selection.html">14. Model Selection &amp; Evaluation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generative Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="gmms.html">15. Gaussian Mixture Models (Clustering)</a></li>
<li class="toctree-l1"><a class="reference internal" href="factor-analysis.html">16. Factor Analysis (Dimensionality Reduction)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="prior-and-posterior.html">17. Bayesian Inference: Prior and Posterior</a></li>
<li class="toctree-l1"><a class="reference internal" href="posterior-predictive.html">18. Bayesian Inference: Posterior Predictive</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/probability-continuous.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probability (Continuous)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#differences-between-continuous-and-discrete-probability">10.1. Differences Between Continuous and Discrete Probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-for-discrete-continuous-models">10.2. MLE for Discrete-Continuous Models</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probability-continuous">
<h1><span class="section-number">10. </span>Probability (Continuous)<a class="headerlink" href="#probability-continuous" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import some helper functions (please ignore this!)</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span> 
</pre></div>
</div>
</div>
</div>
<p><strong>Context:</strong> Many real-world data sets include non-discrete values (e.g. a patient’s body-mass index (BMI), the dosage of medicine, and more). Here, we will introduce what you need to know in order to model continuous-valued data.</p>
<p><strong>Challenge:</strong> In many ways, continuous probability is similar to discrete probability. However, there are a few “gotchas” that are important to highlight.</p>
<p><strong>Outline:</strong></p>
<ul class="simple">
<li><p>Introduce and practice the concepts, terminology, and notation behind continuous probability distributions.</p></li>
<li><p>Gain familiarity with several common continuous distributions.</p></li>
</ul>
<section id="differences-between-continuous-and-discrete-probability">
<h2><span class="section-number">10.1. </span>Differences Between Continuous and Discrete Probability<a class="headerlink" href="#differences-between-continuous-and-discrete-probability" title="Permalink to this heading">#</a></h2>
<p>Continuous probability functions the same way as discrete probability, except for a few key differences.</p>
<p><strong>Sample Space of Support:</strong> The support of continuous probability distributions is over “uncountably infinite sets.” If you’re not familiar with this term, that’s ok! In this course, we’ll think about it more as a distribution supported over the real numbers, <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> (or some subset thereof).</p>
<blockquote>
<div><p>Example: Let <span class="math notranslate nohighlight">\(H\)</span> be a continuous RV, describing the distribution of heights in the IHH ER. The support of <span class="math notranslate nohighlight">\(H\)</span> is the interval <span class="math notranslate nohighlight">\((0, \infty)\)</span> on the real line.</p>
</div></blockquote>
<p><strong>Probability Mass Function (PMF):</strong> Continuous probability distributions <em>DO NOT have PMFs</em>; this is because, unlike discrete distributions, we cannot think of continuous distributions in terms of frequency. Let’s illustrate this with an example.</p>
<blockquote>
<div><p>Example: Suppose we are modeling the probability of intoxication as a Bernoulli RV, <span class="math notranslate nohighlight">\(I\)</span>. If we say that the probability of intoxication (or <span class="math notranslate nohighlight">\(I=1\)</span>) is <span class="math notranslate nohighlight">\(0.5\)</span> (meaning <span class="math notranslate nohighlight">\(p_I(1) = 0.5\)</span>), meaning half of our patients will have intoxication. Such a statement about the PMF of a discrete distribution can be immediately translated into intuition about frequency. On the other hand, suppose we have a continuous RV, <span class="math notranslate nohighlight">\(H\)</span>, modeling the height of patients. How can we describe the probability that a patient is 50 inches tall (i.e. what is <span class="math notranslate nohighlight">\(p_H(50)\)</span>?). Let’s try to get some intuition. Of the patients in the data, maybe we have one that’s <span class="math notranslate nohighlight">\(50.1\)</span> inches tall, another that is <span class="math notranslate nohighlight">\(49.9\)</span>, or maybe one that’s <span class="math notranslate nohighlight">\(49.999991\)</span> inches tall—but what are the chances we will observe a patient that is <em>exactly</em> (not approximately) <span class="math notranslate nohighlight">\(50\)</span> inches tall? The answer is: zero. This is because of the arbitrary precision we have on continuous values. So if we can’t describe continuous distributions using PMFs, how else can we describe them? As you will see next, we will have to use a more circuitous route.</p>
</div></blockquote>
<div class="admonition-exercise-why-continuous-distributions-do-not-have-pmfs admonition">
<p class="admonition-title">Exercise: Why continuous distributions do not have PMFs</p>
<p>Demonstrate empirically that continuous distributions do not have valid PMFs via the following procedure:</p>
<ol class="arabic simple">
<li><p>Sample 10,000 values from a Uniform distribution on the range <span class="math notranslate nohighlight">\([0, 1]\)</span> (using <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>). This will draw samples on the range <span class="math notranslate nohighlight">\([0, 1]\)</span> with equal probability.</p></li>
<li><p>Count the number of samples that exactly equal <span class="math notranslate nohighlight">\(0.5\)</span>. How</p></li>
</ol>
</div>
<p><strong>Cumulative Density Function (CDF):</strong> As we showed, we can’t use the frequency of a continuous RV as its probability. But we <em>can</em> ask a different question: what’s the probability that a continuous RV is smaller than or equal to some value. This is called the CDF, which we will denote using <span class="math notranslate nohighlight">\(F\)</span>. What’s interesting about the CDF is that it abides by our intuition of probability as frequencies; we can empirically estimate the CDF by counting all samples for which the variable is <span class="math notranslate nohighlight">\(\leq\)</span> our value of interest. Next, we will use the CDF to define the “continuous RV version” of the PMF. Before moving on, however, let’s illustrate this by continuing with our example of IHH ER patient height.</p>
<blockquote>
<div><p>Example: Let <span class="math notranslate nohighlight">\(F_H(\cdot)\)</span> define the CDF of a continuous RV, <span class="math notranslate nohighlight">\(H\)</span>, describing the height of IHH ER patients. We use <span class="math notranslate nohighlight">\(F_H(h)\)</span> to denote the probability that the height <span class="math notranslate nohighlight">\(H\)</span> is smaller than some specific value, <span class="math notranslate nohighlight">\(h\)</span> (e.g. <span class="math notranslate nohighlight">\(F_H(50)\)</span> is the probability that the patient’s height is <span class="math notranslate nohighlight">\(\leq 50\)</span>). To evaluate <span class="math notranslate nohighlight">\(F_H(50)\)</span> from data, we can simply look at the frequency of patients for which <span class="math notranslate nohighlight">\(H \leq 50\)</span>, just as we did with discrete probability!</p>
</div></blockquote>
<p><strong>Properties of CDFs:</strong> Let <span class="math notranslate nohighlight">\(R\)</span> be an RV with CDF <span class="math notranslate nohighlight">\(F_R(\cdot)\)</span>.</p>
<ol class="arabic">
<li><p><em>The CDF is non-decreasing.</em> When <span class="math notranslate nohighlight">\(r_1 &lt; r_2\)</span>, we also have that <span class="math notranslate nohighlight">\(F_R(r_1) \leq F_R(r_2)\)</span>.</p>
<blockquote>
<div><p>Example: Continuing with our running example, the probability that height is smaller than 50 inches is smaller or equal to the probability that height is smaller than 60 inches: <span class="math notranslate nohighlight">\(F_H(50) \leq F_H(60)\)</span>. This is because the number of patients with <span class="math notranslate nohighlight">\(H \leq 60\)</span> should be <span class="math notranslate nohighlight">\(\geq\)</span> the number of patients with <span class="math notranslate nohighlight">\(H \leq 50\)</span>.</p>
</div></blockquote>
</li>
<li><p><em>The CDF is bounded by <span class="math notranslate nohighlight">\(0\)</span> below and by <span class="math notranslate nohighlight">\(1\)</span> above.</em> Let <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(U\)</span> be the smallest and largest values in the sample space, respectively. Then, <span class="math notranslate nohighlight">\(\lim\limits_{r \rightarrow L} F_R(r) = 0\)</span>, and <span class="math notranslate nohighlight">\(\lim\limits_{r \rightarrow U} F_R(r) = 1\)</span>.</p>
<blockquote>
<div><p>Example: In our running example, <span class="math notranslate nohighlight">\(L = 0\)</span> (people must have a positive height) and <span class="math notranslate nohighlight">\(U = \infty\)</span> (they can be arbitrarily tall). We denote <span class="math notranslate nohighlight">\(\lim\limits_{h \rightarrow 0} F_H(h)\)</span> as the probability that a patient’s height is <span class="math notranslate nohighlight">\(\leq 0\)</span>. Since a patient can’t be 0 inches or less, this limit evaluates to <span class="math notranslate nohighlight">\(0\)</span>. Similarly, <span class="math notranslate nohighlight">\(\lim\limits_{h \rightarrow \infty} F_H(h)\)</span> denotes the probability that a patient’s height is smaller than infinity. Since this is always true, this limit evaluates to <span class="math notranslate nohighlight">\(1\)</span>.</p>
</div></blockquote>
</li>
</ol>
<p>We will now plot the CDF of some different continuous RVs (a uniform distribution and a normal distribution, denoted by <span class="math notranslate nohighlight">\(\mathcal{U}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{N}\)</span>, respectively). Can you check that both properties are satisfied?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpyro</span>
<span class="kn">import</span> <span class="nn">numpyro.distributions</span> <span class="k">as</span> <span class="nn">D</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">))</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">Uniform</span><span class="p">()</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">r</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF of $\mathcal</span><span class="si">{U}</span><span class="s1">[0, 1]$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">Normal</span><span class="p">()</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">r</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF of $\mathcal</span><span class="si">{N}</span><span class="s1">(0, 1)$&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$r$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$F_R(r)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;The CDF of Different Continuous RVs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1fa6f658c7e020a472b450d80376ddbc140b4ce344aa6aa452d376db904dc180.png" src="_images/1fa6f658c7e020a472b450d80376ddbc140b4ce344aa6aa452d376db904dc180.png" />
</div>
</div>
<p><strong>Probability Density Function (PDF):</strong> We will now introduce the PDF—the “continuous RV version of the PMF”—using the CDF. To do this, we will introduce just one more fact about the CDF. This fact will allow us to compute the probability of an RV lying <em>between</em> two values: suppose we have a continuous RV, <span class="math notranslate nohighlight">\(R\)</span> with CDF <span class="math notranslate nohighlight">\(F_R(\cdot)\)</span>, then the probability that <span class="math notranslate nohighlight">\(l &lt; R \leq u\)</span> is given by <span class="math notranslate nohighlight">\(F_R(u) - F_R(l)\)</span>.</p>
<blockquote>
<div><p>Example: Suppose we want to know the probability that a patient’s height is between <span class="math notranslate nohighlight">\(40\)</span> and <span class="math notranslate nohighlight">\(60\)</span> inches. Let’s start by computing the probability that the patient’s height is less than <span class="math notranslate nohighlight">\(60\)</span> inches—but this also includes patients whose height is also less than <span class="math notranslate nohighlight">\(40\)</span> inches (which we want to exclude). To do this, we can subtract the probability that their height is less than <span class="math notranslate nohighlight">\(40\)</span> inches. This gives us <span class="math notranslate nohighlight">\(F_H(60) - F_H(40)\)</span>.</p>
</div></blockquote>
<p>Using our new fact, let’s set up the problem differently. Instead of trying to directly compute the probability of <span class="math notranslate nohighlight">\(R = r\)</span> (which is always 0), let’s compute the probability that <span class="math notranslate nohighlight">\(R\)</span> is <em>super close to</em> <span class="math notranslate nohighlight">\(r\)</span>. We can do this by making up a variable, <span class="math notranslate nohighlight">\(\epsilon\)</span>, that is very small, and computing how the CDF changes from <span class="math notranslate nohighlight">\(F_R(r - \epsilon)\)</span> to <span class="math notranslate nohighlight">\(F_R(r)\)</span>. In other words, we want the instantaneous rate-of-change from <span class="math notranslate nohighlight">\(F_R(r - \epsilon)\)</span> to <span class="math notranslate nohighlight">\(F_R(r)\)</span>, since this rate-of-chance can be thought of as “the inclusion of <span class="math notranslate nohighlight">\(r\)</span>”.</p>
<p>Now, the instantaneous rate-of-change is also known as the derivative. Thus, we define the PDF as the derivative of the CDF:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8e2c771f-2c4f-4435-982f-27b6348c9139">
<span class="eqno">(10.1)<a class="headerlink" href="#equation-8e2c771f-2c4f-4435-982f-27b6348c9139" title="Permalink to this equation">#</a></span>\[\begin{align}
p_R(r) &amp;= \frac{d F_R(r)}{d r}.
\end{align}\]</div>
<p><strong>Properties of PDFs:</strong> Let <span class="math notranslate nohighlight">\(R\)</span> be a continuous RV with PDF <span class="math notranslate nohighlight">\(p_R(\cdot)\)</span>, defined on the sample-space <span class="math notranslate nohighlight">\(S\)</span>.</p>
<ol class="arabic">
<li><p><em>The PDF must integrate to 1.</em> That is, <span class="math notranslate nohighlight">\(\int\limits_{r \in S} p_R(r) dr = 1\)</span>. This is analogous to the fact that discrete probabilities must sum to 1.</p>
<blockquote>
<div><p>Example: If <span class="math notranslate nohighlight">\(R\)</span> is drawn from a Normal distribution, then our sample space is <span class="math notranslate nohighlight">\(S = (-\infty, \infty)\)</span>. We must therefore have that <span class="math notranslate nohighlight">\(\int\limits_{-\infty}^\infty p_R(r) dr = 1\)</span>.</p>
</div></blockquote>
</li>
<li><p><em>The PDF can be greater than 1.</em> This is in contrast to discrete probability, in which the PMF can never be greater than 1.</p>
<blockquote>
<div><p>Example: Examine the plot of the PDF of the normal distribution (with parameters of <span class="math notranslate nohighlight">\(\mu = 0\)</span> and <span class="math notranslate nohighlight">\(\sigma = 0.1\)</span>) below. Notice that it rises above 1.</p>
</div></blockquote>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">r</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$r$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p_R(r)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;The PDF of a continuous RV can be $\geq 1$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/274fe411e27524c3573c21fe54900785e4aa5deb1798b115e0efbf3ff020e6e1.png" src="_images/274fe411e27524c3573c21fe54900785e4aa5deb1798b115e0efbf3ff020e6e1.png" />
</div>
</div>
<div class="admonition-exercise-gaining-comfort-with-commonly-used-continuous-distributions admonition">
<p class="admonition-title">Exercise: Gaining comfort with commonly-used continuous distributions</p>
<p>Browse the Wikipedia pages for the following distributions:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution" rel="noopener noreferrer" target="_blank">Uniform</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Beta_distribution" rel="noopener noreferrer" target="_blank">Beta</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Normal_distribution" rel="noopener noreferrer" target="_blank">Normal (or Gaussian)</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Truncated_normal_distribution" rel="noopener noreferrer" target="_blank">Truncated Normal</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Laplace_distribution" rel="noopener noreferrer" target="_blank">Laplace</a></p></li>
</ul>
<p><strong>Part 1:</strong> For each of the distributions above, plot its PDF. Play with the parameters of each distribution—how does each affect the shape of the distribution? Summarize what you learn.</p>
<p><strong>Part 2:</strong> Answer the following questions:</p>
<ol class="arabic simple">
<li><p>You’re modeling the distribution of heights in the US. Which of the above distributions would you choose and why?</p></li>
<li><p>You have a large collection of antique coins. Unlike modern-day coins, your coins don’t have a 50% probability of landing heads. You’re interested in modeling the distribution of the probability of them landing heads. That is, each coin has a different probability of landing heads—you want to model the distribution of these probabilities. Which of the above distributions would you choose and why?</p></li>
<li><p>You’ve been given a prototype of a new sensor that determines the location of the nearest intergalactic being. The sensor is, on average, correct, but is typically a little off (sometimes it overshoots and sometimes it undershoots the location). Which of the above distributions would you use to describe the error and why?</p></li>
</ol>
<p><em>Hint: On each Wikipedia page, there’s a panel on the right side that summarizes the properties of the distribution (e.g. its support, PDF, example plots, etc.)—all of the information you need is there.</em></p>
</div>
</section>
<section id="mle-for-discrete-continuous-models">
<h2><span class="section-number">10.2. </span>MLE for Discrete-Continuous Models<a class="headerlink" href="#mle-for-discrete-continuous-models" title="Permalink to this heading">#</a></h2>
<p>You’ve recently been contacted by researchers at the IHH’s Center for Telekinesis Research (CTR). The researchers at the IHH’s CTR study the propensity of intergalactic beings for telekinesis—the ability of moving physical objects with their mind (how cool!). At the moment, they are interested in understanding how different physiological conditions affect a being’s telekinetic abilities (measured as a real number, with larger numbers indicating heightened telekinetic abilities). They have collected the following data sets and would like your help in analyzing it. Let’s load it and have a look!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import a bunch of libraries we&#39;ll be using below</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Load the data into a pandas dataframe</span>
<span class="n">csv_fname</span> <span class="o">=</span> <span class="s1">&#39;data/IHH-CTR.csv&#39;</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_fname</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;Patient ID&#39;</span><span class="p">)</span>

<span class="c1"># Print a random sample of patients, just to see what&#39;s in the data</span>
<span class="n">data</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Condition</th>
      <th>Telekinetic-Ability</th>
    </tr>
    <tr>
      <th>Patient ID</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>398</th>
      <td>Allergic Reaction</td>
      <td>0.510423</td>
    </tr>
    <tr>
      <th>3833</th>
      <td>Allergic Reaction</td>
      <td>0.479960</td>
    </tr>
    <tr>
      <th>4836</th>
      <td>Intoxication</td>
      <td>2.043218</td>
    </tr>
    <tr>
      <th>4572</th>
      <td>Allergic Reaction</td>
      <td>-0.443333</td>
    </tr>
    <tr>
      <th>636</th>
      <td>Intoxication</td>
      <td>1.423190</td>
    </tr>
    <tr>
      <th>2545</th>
      <td>Intoxication</td>
      <td>1.392568</td>
    </tr>
    <tr>
      <th>1161</th>
      <td>Intoxication</td>
      <td>2.110151</td>
    </tr>
    <tr>
      <th>2230</th>
      <td>Intoxication</td>
      <td>2.102866</td>
    </tr>
    <tr>
      <th>148</th>
      <td>Intoxication</td>
      <td>1.865081</td>
    </tr>
    <tr>
      <th>2530</th>
      <td>Allergic Reaction</td>
      <td>0.401414</td>
    </tr>
    <tr>
      <th>4070</th>
      <td>Intoxication</td>
      <td>2.271342</td>
    </tr>
    <tr>
      <th>1261</th>
      <td>Allergic Reaction</td>
      <td>-0.455159</td>
    </tr>
    <tr>
      <th>4682</th>
      <td>Entangled Antennas</td>
      <td>-1.713834</td>
    </tr>
    <tr>
      <th>333</th>
      <td>Intoxication</td>
      <td>2.000120</td>
    </tr>
    <tr>
      <th>906</th>
      <td>Intoxication</td>
      <td>1.693633</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="admonition-exercise-modeling-data-from-the-ihh-s-center-for-telekinesis-research admonition">
<p class="admonition-title">Exercise: Modeling Data from the IHH’s Center for Telekinesis Research</p>
<p>Let <span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(A\)</span> denote the RVs representing “Condition” and “Telekinetic-Ability,” respectively. Your goal is to learn a generative model (i.e. a joint distribution) of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(C\)</span>.</p>
<p><strong>Part 1:</strong> Let’s first perform an exploratory data analysis.</p>
<ul class="simple">
<li><p>Visualize the marginals, <span class="math notranslate nohighlight">\(p_C(\cdot)\)</span> and <span class="math notranslate nohighlight">\(p_A(\cdot)\)</span>.</p></li>
<li><p>Visualize the conditional <span class="math notranslate nohighlight">\(p_{A | C}(\cdot | c)\)</span> for every value of <span class="math notranslate nohighlight">\(c\)</span>.</p></li>
<li><p>Can you visualize <span class="math notranslate nohighlight">\(p_{C | A}(c | a)\)</span>? Explain.</p></li>
</ul>
<p><strong>Part 2:</strong> Based on the visualizations, which of the following factorizations of the joint would you prefer to use? And which distributions would you use for each component in the factorization? Explain.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p_{A, C}(a, c) &amp;= p_{A | C}(a | c) \cdot p_C(c) \quad \text{(Option 1)} \\
p_{A, C}(a, c) &amp;= p_{C | A}(c | a) \cdot p_A(a) \quad \text{(Option 2)}
\end{align*}\]</div>
<p><em>Hint: Think of which of the distributions already covered in the course would you use for each component of the joint distribution.</em></p>
<p><strong>Part 3:</strong> Draw a directed graphical model for the joint data likelihood. Write down the log of the joint data likelihood (the joint probability of all <span class="math notranslate nohighlight">\(N\)</span> observations). Both should explicitly depict the parameters of the model that you’d like to learn.</p>
<p><strong>Part 4:</strong> Implement your model in <code class="docutils literal notranslate"><span class="pre">NumPyro</span></code>. Perform the MLE on your model.</p>
<p><strong>Part 5:</strong> Verify your model learned the data distribution well by plotting each component of your joint distribution against the empirical distribution of the data.</p>
<p><strong>Part 6:</strong> Help the researchers interpret your fitted model. Which conditions hinder telekinetic ability, and which enhance it? How can you tell?</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="optimization.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">9. </span>Optimization</p>
      </div>
    </a>
    <a class="right-next"
       href="regression.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11. </span>Regression</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#differences-between-continuous-and-discrete-probability">10.1. Differences Between Continuous and Discrete Probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-for-discrete-continuous-models">10.2. MLE for Discrete-Continuous Models</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <footer>
  <div class="flex-shrink-0 container">
    <div class="row align-items-center">
      <div class="col-6">
        &copy; Copyright 2024 Yaniv Yacoby
      </div>      
      <div class="col-6">
        <img src="_static/img/wc-logo-blue.png" alt="Wellesley College Logo" class="only-light" style="width: 49%; max-width: 120px; float: right; display: block;"/>
        <img src="_static/img/wc-logo-white.png" alt="Wellesley College Logo" class="only-dark" style="width: 49%; max-width: 120px; float: right; display: block;"/>
      </div>
    </div>    
  </div>  
</footer>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>